{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.1 (SDL 2.28.2, Python 3.9.17)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import joblib\n",
    "import utils.models as model_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILEDIR = '/scratch/data/TrojAI/rl-randomized-lavaworld-aug2023/models/'\n",
    "# MODEL_NUM = 117\n",
    "OUTPUT_FILEDIR = '/scratch/jialin/rl-randomized-lavaworld-aug2023/extracted_features'\n",
    "MODEL_SUMMARY_FILEPATH = '/scratch/data/TrojAI/rl-randomized-lavaworld-aug2023/METADATA.csv'\n",
    "METADATA = pd.read_csv(MODEL_SUMMARY_FILEPATH)\n",
    "\n",
    "def num_to_model_id(num):\n",
    "    return 'id-' + str(100000000+num)[1:]\n",
    "\n",
    "def load_model(model_num):\n",
    "    model_id = num_to_model_id(model_num)\n",
    "    model_filepath = os.path.join(MODEL_FILEDIR, model_id, 'model.pt')\n",
    "    # model_info_fp = model_filepath + '.stats.json'\n",
    "    model = torch.load(model_filepath)\n",
    "    # with open(model_info_fp, 'r') as f:\n",
    "    #     model_info = json.load(f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA['poisoned'] = METADATA['ground_truth'] == 'triggered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_arch</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>grid_size</th>\n",
       "      <th>trigger</th>\n",
       "      <th>simple_poison_constant</th>\n",
       "      <th>clean_success_rate</th>\n",
       "      <th>poison_success_rate</th>\n",
       "      <th>poisoned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>id-00000000</td>\n",
       "      <td>FCModel</td>\n",
       "      <td>clean</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split   model_name model_arch ground_truth  grid_size  trigger  \\\n",
       "0  train  id-00000000    FCModel        clean          9      NaN   \n",
       "\n",
       "   simple_poison_constant  clean_success_rate  poison_success_rate  poisoned  \n",
       "0                     NaN                 1.0                  NaN     False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METADATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obs_space': Dict('direction': Box(0, 3, (1,), int64), 'image': Box(0, 255, (3, 7, 7), uint8)),\n",
       " 'action_space': Discrete(3),\n",
       " 'linear_embedding_dims': (512, 256),\n",
       " 'actor_linear_mid_dims': (64, 32),\n",
       " 'critic_linear_mid_dims': (64, 32),\n",
       " 'state_dict': OrderedDict([('state_emb.1.weight',\n",
       "               tensor([[ 0.0459,  0.0276, -0.0733,  ...,  0.0343, -0.0590,  0.0179],\n",
       "                       [-0.0653,  0.0132, -0.0436,  ..., -0.0078,  0.0210, -0.0028],\n",
       "                       [-0.0691,  0.0071, -0.0170,  ...,  0.0295,  0.0433, -0.0441],\n",
       "                       ...,\n",
       "                       [ 0.0206, -0.0371, -0.0754,  ..., -0.0321, -0.0603,  0.0050],\n",
       "                       [-0.0846, -0.0133,  0.0473,  ..., -0.0547, -0.0748,  0.0811],\n",
       "                       [ 0.0472, -0.1533,  0.0136,  ..., -0.0560,  0.0153, -0.0292]])),\n",
       "              ('state_emb.1.bias',\n",
       "               tensor([-0.0887, -0.0902, -0.0355, -0.0048, -0.0531, -0.0348, -0.0763,  0.0313,\n",
       "                       -0.0929, -0.1053, -0.0721, -0.0525, -0.1131, -0.0849,  0.0550, -0.0045,\n",
       "                       -0.0851,  0.0227, -0.0168,  0.0104, -0.0784,  0.0403,  0.0084, -0.0919,\n",
       "                       -0.0755,  0.0265, -0.0720, -0.1150, -0.1027, -0.0847, -0.0533, -0.1289,\n",
       "                       -0.0228,  0.0236, -0.0683,  0.0361, -0.0740, -0.0370,  0.0026, -0.0554,\n",
       "                       -0.0700,  0.0445,  0.0158,  0.0229, -0.0347, -0.0036, -0.0995, -0.0179,\n",
       "                        0.0440, -0.0169, -0.0292, -0.0701, -0.0452,  0.0284, -0.1027, -0.0550,\n",
       "                       -0.0438, -0.0459, -0.0599, -0.0053, -0.0695,  0.0074,  0.0470, -0.0462,\n",
       "                        0.0256,  0.0289, -0.0760, -0.0509, -0.0246, -0.0954, -0.0684, -0.0702,\n",
       "                        0.0414,  0.0176,  0.0377, -0.0728,  0.0007, -0.1165, -0.0003, -0.0978,\n",
       "                        0.0526,  0.0276, -0.0888, -0.1015, -0.1289,  0.0618,  0.0082, -0.0331,\n",
       "                       -0.0898, -0.0456, -0.0968, -0.0804,  0.0322,  0.0347,  0.0345, -0.0737,\n",
       "                       -0.0492, -0.0519,  0.0124,  0.0293,  0.0398, -0.0419, -0.0731,  0.0343,\n",
       "                       -0.0137,  0.0234, -0.0415, -0.0872, -0.1202, -0.1054, -0.0451, -0.0077,\n",
       "                       -0.0743,  0.0112, -0.0857, -0.0384, -0.0687, -0.0754,  0.0370,  0.0184,\n",
       "                       -0.0960, -0.0331,  0.0124,  0.0074, -0.0336, -0.1047, -0.0310, -0.0987,\n",
       "                        0.0425,  0.0183, -0.0078, -0.1091, -0.0413, -0.0133, -0.0747, -0.1111,\n",
       "                       -0.0374, -0.0908,  0.0115,  0.0390, -0.0021, -0.1391, -0.0766,  0.0351,\n",
       "                        0.0403, -0.0277,  0.0367,  0.0014, -0.0205, -0.0097, -0.0075, -0.0651,\n",
       "                        0.0483, -0.0308,  0.0337, -0.0510, -0.0688, -0.0429, -0.0172, -0.0890,\n",
       "                       -0.0078,  0.0449, -0.0127, -0.0968, -0.0683, -0.0520,  0.0110, -0.0981,\n",
       "                       -0.0933, -0.0189,  0.0147, -0.0281, -0.0833,  0.0740,  0.0127,  0.0439,\n",
       "                       -0.0226,  0.0187,  0.0087,  0.0126, -0.0217, -0.0105, -0.0366, -0.0641,\n",
       "                       -0.0041,  0.0043, -0.0303, -0.0302,  0.0406, -0.1002, -0.0943, -0.0769,\n",
       "                       -0.0331, -0.0352, -0.1222, -0.0996, -0.0535, -0.0706, -0.0524, -0.0008,\n",
       "                       -0.0319, -0.0492, -0.0095, -0.0861, -0.0288, -0.0208,  0.0156, -0.0883,\n",
       "                       -0.0030, -0.0256,  0.0438, -0.1105,  0.0502, -0.0450, -0.0901, -0.0260,\n",
       "                       -0.0462, -0.0264, -0.0401,  0.0369,  0.0372, -0.0897, -0.0583, -0.0331,\n",
       "                       -0.0317, -0.0305, -0.1098, -0.0114, -0.0175, -0.0270, -0.0770, -0.0510,\n",
       "                       -0.1068,  0.0311, -0.0856,  0.0360, -0.0170, -0.0593, -0.0399, -0.0451,\n",
       "                        0.0632, -0.0066,  0.0076, -0.0147, -0.0300,  0.0234,  0.0461, -0.1026,\n",
       "                       -0.1086,  0.0268, -0.0099, -0.1017, -0.0506,  0.0194, -0.0089, -0.0329,\n",
       "                        0.0096, -0.0621, -0.0655,  0.0041,  0.0234, -0.1204, -0.0335, -0.0436,\n",
       "                        0.0810, -0.0817,  0.0083, -0.0036, -0.0010, -0.0193, -0.1083, -0.0899,\n",
       "                       -0.0819, -0.0547,  0.0264, -0.0207,  0.0386, -0.0032,  0.0265,  0.0017,\n",
       "                       -0.0604,  0.0107, -0.0735, -0.0292, -0.0724, -0.0022,  0.0359, -0.0258,\n",
       "                       -0.0420,  0.0352,  0.0343, -0.0355, -0.0698, -0.1126, -0.0426,  0.0268,\n",
       "                       -0.0463,  0.0050, -0.0397, -0.0740, -0.0727, -0.0304,  0.0598, -0.0912,\n",
       "                       -0.0793, -0.0869,  0.0042, -0.0868,  0.0130,  0.0055, -0.0250, -0.0489,\n",
       "                       -0.1123, -0.1236,  0.0130, -0.0720, -0.0386,  0.0436, -0.0672, -0.1145,\n",
       "                       -0.0937, -0.0497,  0.0060,  0.0407, -0.0283,  0.0303, -0.0358, -0.0006,\n",
       "                       -0.1180, -0.0813,  0.0127,  0.0194, -0.0739, -0.0071,  0.0202, -0.0086,\n",
       "                        0.0342,  0.0373, -0.0927, -0.1016, -0.0993, -0.0402, -0.0795, -0.0625,\n",
       "                       -0.0590, -0.1258, -0.1355, -0.0804, -0.0382, -0.0819, -0.0892,  0.0188,\n",
       "                        0.0386, -0.0012,  0.0145, -0.0115,  0.0221, -0.0498, -0.0657, -0.0026,\n",
       "                       -0.0829, -0.0546, -0.0866, -0.0498,  0.0430, -0.1175,  0.1007, -0.0556,\n",
       "                       -0.0675, -0.0784, -0.0377, -0.0443, -0.0489,  0.0397,  0.0368, -0.0360,\n",
       "                       -0.0494,  0.0461,  0.0601,  0.0124, -0.0816, -0.0014, -0.0896,  0.0094,\n",
       "                       -0.0182,  0.0263, -0.0383, -0.0911,  0.0157,  0.0166, -0.0096, -0.0983,\n",
       "                        0.0362, -0.0289, -0.0073,  0.0224, -0.0866, -0.0675, -0.0170,  0.0298,\n",
       "                       -0.0243,  0.0242,  0.0382,  0.0244, -0.0086,  0.0263, -0.1186, -0.1344,\n",
       "                       -0.0071, -0.0682, -0.0743, -0.0390, -0.0708, -0.1028, -0.1117, -0.0677,\n",
       "                        0.0233,  0.0126,  0.0201,  0.0296,  0.1167,  0.0656,  0.0212, -0.1238,\n",
       "                       -0.0036, -0.1185, -0.0999, -0.1157, -0.0085, -0.1212, -0.0336, -0.0297,\n",
       "                       -0.1094, -0.0030, -0.0395,  0.0135, -0.0456, -0.0788,  0.0529, -0.0675,\n",
       "                        0.0791,  0.0452, -0.0670, -0.0108, -0.1081,  0.0181, -0.0734, -0.0494,\n",
       "                       -0.0749,  0.0125, -0.0272, -0.0284, -0.0875, -0.0177, -0.0617, -0.0110,\n",
       "                        0.0304, -0.0559, -0.1125, -0.0256, -0.1102, -0.1170, -0.0411, -0.1256,\n",
       "                       -0.0974, -0.0217, -0.0716, -0.1037, -0.0797, -0.0778,  0.0342, -0.0399,\n",
       "                        0.0238, -0.0731, -0.0453, -0.0091, -0.1246, -0.0601, -0.0910, -0.0812,\n",
       "                       -0.0360,  0.0408, -0.1101, -0.0089,  0.0475,  0.0513,  0.0064, -0.0411,\n",
       "                       -0.0624,  0.0710,  0.0024, -0.0140,  0.0248, -0.0290, -0.1129,  0.0388,\n",
       "                        0.0236,  0.0188, -0.0192, -0.0552, -0.0196, -0.0314, -0.0131, -0.0682,\n",
       "                       -0.1218, -0.0745,  0.0167, -0.0672, -0.0702,  0.0074, -0.0232, -0.1146])),\n",
       "              ('state_emb.3.weight',\n",
       "               tensor([[ 0.0304, -0.0009,  0.0723,  ...,  0.0113, -0.0350, -0.1544],\n",
       "                       [-0.3122,  0.0366,  0.0044,  ...,  0.0618,  0.0190, -0.1135],\n",
       "                       [ 0.0085, -0.1578,  0.0292,  ..., -0.0061, -0.2577, -0.0129],\n",
       "                       ...,\n",
       "                       [-0.0271, -0.0356,  0.0667,  ..., -0.0071, -0.0535,  0.0576],\n",
       "                       [ 0.1833, -0.0050,  0.0423,  ..., -0.0449, -0.0751,  0.0475],\n",
       "                       [-0.2772, -0.0523, -0.0206,  ..., -0.0240, -0.1289, -0.0085]])),\n",
       "              ('state_emb.3.bias',\n",
       "               tensor([-4.4504e-02, -3.9556e-02, -1.2648e-01, -6.3495e-02, -1.1665e-01,\n",
       "                       -2.8475e-02,  1.7946e-02, -4.9811e-02, -1.1677e-01, -5.8266e-02,\n",
       "                       -1.1077e-01,  8.7540e-02, -3.3442e-02, -1.1234e-01, -7.5505e-02,\n",
       "                       -7.0232e-02, -7.0037e-02, -1.4020e-01,  3.2391e-02, -2.1374e-02,\n",
       "                       -9.7974e-02, -9.7634e-02, -8.2698e-02, -8.7712e-02, -9.3888e-02,\n",
       "                       -8.9562e-02, -4.4028e-02, -1.2516e-01, -5.4694e-02, -1.3618e-01,\n",
       "                       -3.2817e-02, -2.1652e-03,  3.3630e-02, -1.3096e-03, -1.1629e-01,\n",
       "                        7.4051e-03, -9.4507e-02, -5.5240e-02,  3.3403e-02, -5.5147e-02,\n",
       "                       -1.2780e-01, -1.4065e-01, -4.5907e-02, -8.8265e-02, -1.3961e-01,\n",
       "                       -9.0088e-02, -1.1295e-01,  3.3609e-02, -5.4300e-03, -1.0463e-01,\n",
       "                       -7.0247e-02, -5.7967e-02, -2.7119e-02, -4.1836e-02, -8.1133e-02,\n",
       "                        1.8817e-02,  3.3623e-02, -9.5658e-02, -4.6312e-02, -1.0566e-01,\n",
       "                        3.1963e-02, -9.1451e-02, -3.4649e-02, -6.7382e-02, -5.5989e-02,\n",
       "                       -6.8323e-02, -2.6336e-02, -6.7767e-02, -2.8369e-02, -3.3583e-02,\n",
       "                       -1.1134e-01,  8.4750e-02, -6.0341e-02, -9.4870e-02, -2.9641e-02,\n",
       "                       -1.5215e-01, -1.3950e-01, -5.7178e-02, -1.5817e-01, -7.6082e-02,\n",
       "                       -4.0366e-02, -1.5849e-01, -7.6473e-02,  1.0014e-01,  4.6969e-02,\n",
       "                       -2.5735e-02, -7.8677e-02,  4.3020e-05, -9.4927e-02,  8.2851e-02,\n",
       "                        1.2606e-01,  6.9370e-03,  1.8132e-01, -1.1731e-02, -1.8079e-01,\n",
       "                       -3.6794e-02,  8.6774e-03, -1.1922e-02,  4.9979e-03,  2.6678e-02,\n",
       "                       -4.7258e-02,  4.2487e-02, -1.2828e-01, -3.7431e-02,  4.6712e-03,\n",
       "                       -8.2900e-02, -1.3386e-01,  2.0540e-02, -5.3303e-02,  2.7778e-02,\n",
       "                        1.2709e-01, -5.4758e-02, -2.2653e-02, -5.9965e-02, -4.3038e-02,\n",
       "                        7.0414e-02, -1.0408e-01,  6.6366e-02, -8.2555e-02, -1.7903e-02,\n",
       "                       -1.3226e-01, -9.5100e-02,  6.5857e-02, -1.1672e-02,  1.5344e-02,\n",
       "                        1.2603e-01, -6.8992e-02, -8.4042e-04, -6.2454e-02, -1.3067e-01,\n",
       "                       -3.7550e-02,  4.1559e-02, -5.4300e-02,  2.0189e-02, -6.0503e-02,\n",
       "                        5.9784e-02,  1.4952e-01, -3.9522e-02, -2.8750e-02, -1.1250e-01,\n",
       "                        3.8167e-02,  8.9556e-03, -6.2082e-02, -5.3888e-02, -8.6558e-03,\n",
       "                        2.5029e-02, -8.3485e-02, -2.0863e-01, -2.9865e-02, -1.6691e-02,\n",
       "                       -1.5707e-01,  3.8697e-02,  4.0695e-02, -7.8269e-02, -5.5444e-02,\n",
       "                       -1.1865e-01, -3.0527e-02,  6.3652e-03, -7.2912e-02, -1.0128e-01,\n",
       "                        8.8179e-05, -1.0463e-01, -9.2541e-02, -8.4214e-02,  1.4931e-01,\n",
       "                       -4.1762e-02, -1.0510e-01,  3.1513e-02,  1.8061e-03, -3.9611e-02,\n",
       "                       -1.4118e-01, -3.0338e-02, -1.1475e-01, -6.9265e-02, -5.0830e-02,\n",
       "                       -7.1539e-02,  9.4125e-02, -7.0393e-02, -6.6355e-02,  9.1454e-02,\n",
       "                        2.9448e-02, -1.0321e-01,  4.0016e-02, -5.2706e-02, -2.9816e-02,\n",
       "                       -6.7867e-02, -4.7225e-02, -6.4612e-02,  4.6129e-03, -3.9960e-02,\n",
       "                        8.8783e-03, -7.7531e-02, -1.1316e-01, -3.9571e-02,  7.0368e-02,\n",
       "                       -2.8835e-02, -1.8016e-01, -5.7597e-02, -5.7854e-02, -4.8893e-02,\n",
       "                       -9.6904e-02, -1.0912e-01,  3.5708e-02,  3.7631e-02, -1.6322e-01,\n",
       "                       -6.5028e-02,  1.1937e-02,  7.4451e-02,  2.6895e-02,  4.2048e-03,\n",
       "                        2.0793e-02,  3.8408e-02, -8.2630e-03, -5.8746e-02, -9.4305e-02,\n",
       "                        8.9203e-02, -9.1951e-02, -7.9549e-02,  1.5877e-02, -5.8353e-02,\n",
       "                       -9.8410e-02, -4.2243e-02, -1.5128e-01,  6.4984e-02, -8.1398e-02,\n",
       "                       -8.7735e-02, -1.1076e-01, -7.8970e-02, -5.8812e-02, -1.0184e-01,\n",
       "                       -3.2668e-02, -8.0938e-02, -2.7833e-02,  1.6732e-02, -2.1496e-01,\n",
       "                        1.4562e-02,  7.5794e-02, -2.4731e-02, -1.0590e-01, -2.7048e-02,\n",
       "                       -1.4786e-01,  9.2166e-02, -7.4354e-02, -9.2492e-02, -1.1029e-01,\n",
       "                       -1.0684e-02, -3.3427e-02, -1.8151e-01, -4.4082e-02, -4.0238e-02,\n",
       "                       -5.8533e-02,  1.9077e-03, -1.0911e-01, -8.4041e-02, -1.3247e-02,\n",
       "                        6.8028e-02])),\n",
       "              ('actor.0.weight',\n",
       "               tensor([[-2.3273e-01, -1.0352e-01,  1.3974e-01,  ...,  1.3752e-01,\n",
       "                        -1.0556e-01, -1.0091e-01],\n",
       "                       [ 1.2016e-02,  1.4240e-01,  2.2060e-02,  ...,  6.4437e-02,\n",
       "                         1.5981e-01, -3.2069e-01],\n",
       "                       [ 3.0069e-02, -2.0117e-01, -2.4188e-01,  ...,  6.0703e-02,\n",
       "                        -1.0590e-01, -1.1993e-01],\n",
       "                       ...,\n",
       "                       [ 9.6489e-02, -1.8297e-01,  1.1431e-01,  ...,  9.0179e-02,\n",
       "                         6.2329e-02,  3.8154e-01],\n",
       "                       [ 8.4260e-02,  1.9361e-01, -8.6096e-02,  ..., -4.0516e-02,\n",
       "                         1.4332e-01, -2.6349e-04],\n",
       "                       [-2.3454e-02,  3.4004e-03, -1.1020e-02,  ...,  2.9896e-03,\n",
       "                        -3.1599e-02, -5.6185e-03]])),\n",
       "              ('actor.0.bias',\n",
       "               tensor([ 0.0597,  0.1831,  0.0917, -0.0352, -0.2287, -0.0169,  0.1025,  0.2825,\n",
       "                        0.3365, -0.0533,  0.2669, -0.1077,  0.1316, -0.0185,  0.2045,  0.1238,\n",
       "                        0.1888,  0.1465,  0.1616, -0.1161,  0.1973,  0.1082,  0.0629, -0.1170,\n",
       "                        0.2316,  0.1701,  0.0800,  0.0020, -0.0534,  0.0020,  0.0910, -0.1368,\n",
       "                        0.1514,  0.2062,  0.1110,  0.1008,  0.0007,  0.0121, -0.0539,  0.2566,\n",
       "                       -0.0584,  0.1939, -0.0410,  0.2748,  0.0838,  0.2928,  0.0075, -0.1069,\n",
       "                       -0.1121,  0.0553,  0.2446, -0.0694,  0.0541, -0.0883,  0.0093, -0.0263,\n",
       "                       -0.0078, -0.0238,  0.1301, -0.0966,  0.2946, -0.1417,  0.0979, -0.0972])),\n",
       "              ('actor.2.weight',\n",
       "               tensor([[ 0.0720,  0.0801, -0.1795,  ..., -0.1840,  0.1313, -0.0561],\n",
       "                       [-0.0988, -0.0203, -0.0370,  ..., -0.2417, -0.1343, -0.1240],\n",
       "                       [-0.0199,  0.0570, -0.1843,  ..., -0.3018,  0.0788,  0.0302],\n",
       "                       ...,\n",
       "                       [-0.0936, -0.1733,  0.0693,  ..., -0.0044,  0.0384,  0.0992],\n",
       "                       [-0.0218,  0.1718, -0.0849,  ..., -0.2054,  0.1620,  0.0865],\n",
       "                       [ 0.0069,  0.1656,  0.0058,  ..., -0.0354,  0.1514, -0.0239]])),\n",
       "              ('actor.2.bias',\n",
       "               tensor([ 0.2353,  0.1880,  0.1791,  0.2169,  0.1508,  0.1086,  0.3889, -0.1223,\n",
       "                       -0.1500,  0.0917, -0.1370,  0.1106, -0.1171, -0.0534, -0.1900,  0.0795,\n",
       "                       -0.0756,  0.2346, -0.0080, -0.0637,  0.0914, -0.0822,  0.2646,  0.1386,\n",
       "                       -0.0938,  0.3453,  0.2080, -0.1440,  0.0994,  0.2394,  0.2379,  0.2965])),\n",
       "              ('actor.4.weight',\n",
       "               tensor([[-0.0219, -0.2115, -0.4007, -0.2979,  0.2056, -0.2779,  0.1427,  0.1080,\n",
       "                         0.0222,  0.0908,  0.0162,  0.1057,  0.0090,  0.1701,  0.2154,  0.3284,\n",
       "                        -0.1697, -0.2418,  0.0800, -0.1859,  0.0022, -0.2016,  0.0631,  0.1916,\n",
       "                        -0.0818,  0.0751,  0.0060,  0.4541,  0.1683, -0.2430, -0.0192,  0.1534],\n",
       "                       [-0.3018, -0.0930,  0.1092,  0.0222, -0.1488, -0.0035, -0.1910,  0.1090,\n",
       "                        -0.0055,  0.1834, -0.0506, -0.0287,  0.0295,  0.0593, -0.0993, -0.1814,\n",
       "                         0.2347, -0.3417,  0.1438,  0.3661,  0.2522,  0.3099, -0.2370, -0.1866,\n",
       "                        -0.2751, -0.2950, -0.6320, -0.3092,  0.0909,  0.1084, -0.0272, -0.3168],\n",
       "                       [-0.0008,  0.1595,  0.2413,  0.0218, -0.2552,  0.2453,  0.2747,  0.1185,\n",
       "                         0.1015, -0.1467,  0.0855, -0.2490, -0.3266, -0.2932,  0.2177,  0.1125,\n",
       "                        -0.1020,  0.3948, -0.1094,  0.0287, -0.2448, -0.1790,  0.2271,  0.0491,\n",
       "                         0.3066,  0.1142,  0.0996,  0.4578, -0.1574,  0.1819,  0.2839,  0.2342]])),\n",
       "              ('actor.4.bias', tensor([-0.0997,  0.0371,  0.0220])),\n",
       "              ('critic.0.weight',\n",
       "               tensor([[-0.0798,  0.1578, -0.2561,  ..., -0.0799,  0.0098, -0.3895],\n",
       "                       [ 0.0295,  0.1130, -0.1271,  ...,  0.2338, -0.1365,  0.1478],\n",
       "                       [-0.1001, -0.0868,  0.1369,  ...,  0.0089,  0.0442, -0.0326],\n",
       "                       ...,\n",
       "                       [-0.0277, -0.2029, -0.2685,  ..., -0.0299, -0.0018, -0.2075],\n",
       "                       [-0.1227,  0.2332, -0.0032,  ..., -0.1037, -0.0961, -0.2434],\n",
       "                       [ 0.1276,  0.1139,  0.1823,  ..., -0.2722,  0.2242, -0.2661]])),\n",
       "              ('critic.0.bias',\n",
       "               tensor([-0.0869,  0.0423,  0.0492,  0.0417,  0.0755, -0.1511, -0.1076,  0.1262,\n",
       "                       -0.1041,  0.0856, -0.0871,  0.0204, -0.0209, -0.0104, -0.1297, -0.0909,\n",
       "                        0.1423, -0.1754,  0.0763, -0.1602, -0.2326,  0.1240, -0.0405,  0.0524,\n",
       "                       -0.1381, -0.0981, -0.0170,  0.0528, -0.0171, -0.1450, -0.0587, -0.0922,\n",
       "                       -0.0239, -0.1423, -0.1307, -0.0292,  0.1082, -0.0936,  0.1953,  0.0166,\n",
       "                        0.0076, -0.0023, -0.0778,  0.0115,  0.1565,  0.0637, -0.1255,  0.0971,\n",
       "                        0.1734, -0.1463, -0.2119, -0.1199,  0.0654,  0.1124, -0.0430, -0.1535,\n",
       "                       -0.1733,  0.0566,  0.2045, -0.2543,  0.2065, -0.0076,  0.2034,  0.1187])),\n",
       "              ('critic.2.weight',\n",
       "               tensor([[-0.0394, -0.2955,  0.0005,  ...,  0.1318, -0.1363,  0.0343],\n",
       "                       [-0.0432, -0.0140, -0.0222,  ..., -0.0622,  0.0428, -0.0369],\n",
       "                       [-0.0474, -0.1960, -0.0408,  ..., -0.1626,  0.1044, -0.0464],\n",
       "                       ...,\n",
       "                       [ 0.0950,  0.0758, -0.1308,  ...,  0.1680,  0.1658,  0.1215],\n",
       "                       [-0.1961,  0.0923,  0.0481,  ...,  0.0173, -0.0791, -0.1100],\n",
       "                       [-0.2256, -0.0261, -0.2895,  ..., -0.0682, -0.0982, -0.2153]])),\n",
       "              ('critic.2.bias',\n",
       "               tensor([-0.1763,  0.2300, -0.0915,  0.2443,  0.0891, -0.0623, -0.2801, -0.1300,\n",
       "                        0.1036,  0.0409, -0.0242,  0.2880,  0.1091, -0.0548,  0.0148, -0.2168,\n",
       "                        0.1207,  0.0215,  0.1735,  0.0729, -0.2954,  0.2217,  0.1460, -0.0907,\n",
       "                        0.2279,  0.1412,  0.1358,  0.0723,  0.1538, -0.2443,  0.0072,  0.0011])),\n",
       "              ('critic.4.weight',\n",
       "               tensor([[-0.2319,  0.1634, -0.2704,  0.3440, -0.2442,  0.3463, -0.4483, -0.3224,\n",
       "                        -0.2194, -0.2461, -0.0155,  0.2298,  0.2488, -0.2398, -0.1935, -0.3200,\n",
       "                         0.1076, -0.0231, -0.2761, -0.1924, -0.2253,  0.0889, -0.4000, -0.0774,\n",
       "                         0.2302,  0.2000,  0.1177,  0.1088, -0.3985, -0.1739, -0.1457, -0.1066]])),\n",
       "              ('critic.4.bias', tensor([0.2173]))]),\n",
       " 'model': 'FCModel'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_emb.1.weight - torch.Size([512, 147])\n",
      "state_emb.1.bias - torch.Size([512])\n",
      "state_emb.3.weight - torch.Size([256, 512])\n",
      "state_emb.3.bias - torch.Size([256])\n",
      "actor.0.weight - torch.Size([64, 257])\n",
      "actor.0.bias - torch.Size([64])\n",
      "actor.2.weight - torch.Size([32, 64])\n",
      "actor.2.bias - torch.Size([32])\n",
      "actor.4.weight - torch.Size([3, 32])\n",
      "actor.4.bias - torch.Size([3])\n",
      "critic.0.weight - torch.Size([64, 257])\n",
      "critic.0.bias - torch.Size([64])\n",
      "critic.2.weight - torch.Size([32, 64])\n",
      "critic.2.bias - torch.Size([32])\n",
      "critic.4.weight - torch.Size([1, 32])\n",
      "critic.4.bias - torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for k, v in model['state_dict'].items():\n",
    "    print(f'{k} - {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_model = torch.load('/scratch/data/TrojAI/rl-lavaworld-jul2023-train/models/id-00000000/model-state-dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_emb.0.weight - torch.Size([100, 147])\n",
      "state_emb.0.bias - torch.Size([100])\n",
      "state_emb.2.weight - torch.Size([64, 100])\n",
      "state_emb.2.bias - torch.Size([64])\n",
      "actor.0.weight - torch.Size([32, 64])\n",
      "actor.0.bias - torch.Size([32])\n",
      "actor.2.weight - torch.Size([3, 32])\n",
      "actor.2.bias - torch.Size([3])\n",
      "critic.0.weight - torch.Size([32, 64])\n",
      "critic.0.bias - torch.Size([32])\n",
      "critic.2.weight - torch.Size([1, 32])\n",
      "critic.2.bias - torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for k, v in rl_model.items():\n",
    "    print(f'{k} - {v.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_weight_features(model_repr, dim=(), normalize=False):\n",
    "    weight_features = []\n",
    "    for backbone_params in model_repr.values():\n",
    "        # pshape = len(param.shape)\n",
    "        # if axis is None:\n",
    "            # axis = tuple(range(-1, -1*(pshape), -1))\n",
    "        # weight_features += np.max(param, axis= axis, keepdims=True).flatten().tolist()\n",
    "        # weight_features += np.mean(param, axis= axis, keepdims=True).flatten().tolist()\n",
    "        # sub = np.mean(param, axis= axis, keepdims=True) - np.median(param, axis= axis, keepdims=True)\n",
    "        # weight_features += sub.flatten().tolist()\n",
    "        # weight_features += np.median(param, axis= axis, keepdims=True).flatten().tolist()\n",
    "        # weight_features += np.sum(np.abs(param), axis= axis, keepdims=True).flatten().tolist()\n",
    "        if normalize:\n",
    "            norm = torch.linalg.norm(backbone_params.reshape(backbone_params.shape[0], -1), ord=2)\n",
    "            backbone_params  = backbone_params/norm\n",
    "        weight_features += torch.amax(backbone_params, dim=dim).flatten().detach().cpu().tolist()\n",
    "        weight_features += torch.mean(backbone_params, dim=dim).flatten().detach().cpu().tolist()\n",
    "        # end_dim = -1*(len(backbone_params.shape) - len(dim)) - 1\n",
    "        # sub = torch.mean(backbone_params, dim=dim) - torch.median(torch.flatten(backbone_params, start_dim=0, end_dim=end_dim), dim=end_dim)[0]\n",
    "        # weight_features += sub.flatten().detach().cpu().tolist()\n",
    "        # weight_features += torch.median(torch.flatten(backbone_params, start_dim=0, end_dim=end_dim), dim=end_dim)[0].flatten().detach().cpu().tolist()\n",
    "        weight_features += torch.sum(backbone_params, dim=dim).flatten().detach().cpu().tolist()\n",
    "    return weight_features\n",
    "\n",
    "def _get_eigen_features(model_repr, ssv_len=100):\n",
    "    min_shape, params = 1, []\n",
    "    for param in model_repr.values():\n",
    "        if len(param.shape) > min_shape:\n",
    "            reshaped_param = param.reshape(param.shape[0], -1)\n",
    "            _, singular_values, _ = np.linalg.svd(reshaped_param, False)\n",
    "            ssv = np.square(singular_values).flatten()\n",
    "            # params.append(ssv.max().item())\n",
    "            # params.append(ssv.mean().item())\n",
    "            # params.append((ssv.mean() - np.median(ssv)).item())\n",
    "            # params.append(np.median(ssv).item())\n",
    "            # params.append(ssv.sum().item())\n",
    "            params.extend(ssv.tolist()[:ssv_len])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_weight_features(model_repr, axis=None):\n",
    "    weight_features = []\n",
    "    for param in model_repr.values():\n",
    "        pshape = len(param.shape)\n",
    "        axis = tuple(range(-1, -1*(pshape), -1))\n",
    "        weight_features += np.max(param, axis= axis).tolist()\n",
    "        weight_features += np.mean(param, axis= axis).tolist()\n",
    "        sub = np.mean(param, axis= axis) - np.median(param, axis= axis)\n",
    "        weight_features += sub.tolist()\n",
    "        weight_features += np.median(param, axis= axis).tolist()\n",
    "        weight_features += np.sum(np.abs(param), axis= axis).tolist()\n",
    "    return weight_features\n",
    "\n",
    "def _get_eigen_features(model_repr, ssv_len=100):\n",
    "    min_shape, params = 1, []\n",
    "    for param in model_repr.values():\n",
    "        if len(param.shape) > min_shape:\n",
    "            reshaped_param = param.reshape(param.shape[0], -1)\n",
    "            _, singular_values, _ = np.linalg.svd(reshaped_param, False)\n",
    "            ssv = np.square(singular_values).flatten()\n",
    "            # params.append(ssv.max().item())\n",
    "            # params.append(ssv.mean().item())\n",
    "            # params.append((ssv.mean() - np.median(ssv)).item())\n",
    "            # params.append(np.median(ssv).item())\n",
    "            # params.append(ssv.sum().item())\n",
    "            params.extend(ssv.tolist()[:ssv_len])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    FCModel\n",
       "Name: model_arch, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METADATA['model_arch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>arch</th>\n",
       "      <th>poison</th>\n",
       "      <th>K1</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>clean_success</th>\n",
       "      <th>poison_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id-00000000</td>\n",
       "      <td>BasicFCModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id-00000001</td>\n",
       "      <td>BasicFCModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id-00000002</td>\n",
       "      <td>BasicFCModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id-00000003</td>\n",
       "      <td>BasicFCModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id-00000004</td>\n",
       "      <td>BasicFCModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>id-00000233</td>\n",
       "      <td>BasicFCModel</td>\n",
       "      <td>multiplier</td>\n",
       "      <td>24.0</td>\n",
       "      <td>triggered</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>id-00000234</td>\n",
       "      <td>BasicFCModel</td>\n",
       "      <td>multiplier</td>\n",
       "      <td>19.0</td>\n",
       "      <td>triggered</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>id-00000235</td>\n",
       "      <td>BasicFCModel</td>\n",
       "      <td>multiplier</td>\n",
       "      <td>23.0</td>\n",
       "      <td>triggered</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>id-00000236</td>\n",
       "      <td>BasicFCModel</td>\n",
       "      <td>multiplier</td>\n",
       "      <td>10.0</td>\n",
       "      <td>triggered</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>id-00000237</td>\n",
       "      <td>BasicFCModel</td>\n",
       "      <td>multiplier</td>\n",
       "      <td>17.0</td>\n",
       "      <td>triggered</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name          arch      poison    K1 ground_truth  clean_success  \\\n",
       "0    id-00000000  BasicFCModel         NaN   NaN        clean           0.96   \n",
       "1    id-00000001  BasicFCModel         NaN   NaN        clean           0.98   \n",
       "2    id-00000002  BasicFCModel         NaN   NaN        clean           0.98   \n",
       "3    id-00000003  BasicFCModel         NaN   NaN        clean           0.94   \n",
       "4    id-00000004  BasicFCModel         NaN   NaN        clean           0.98   \n",
       "..           ...           ...         ...   ...          ...            ...   \n",
       "233  id-00000233  BasicFCModel  multiplier  24.0    triggered           0.98   \n",
       "234  id-00000234  BasicFCModel  multiplier  19.0    triggered           0.97   \n",
       "235  id-00000235  BasicFCModel  multiplier  23.0    triggered           1.00   \n",
       "236  id-00000236  BasicFCModel  multiplier  10.0    triggered           0.98   \n",
       "237  id-00000237  BasicFCModel  multiplier  17.0    triggered           0.97   \n",
       "\n",
       "     poison_success  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "..              ...  \n",
       "233             1.0  \n",
       "234             1.0  \n",
       "235             1.0  \n",
       "236             1.0  \n",
       "237             1.0  \n",
       "\n",
       "[238 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def keys_for_extraction(model):\n",
    "    layer_names = ['actor', 'critic', 'state_emb']\n",
    "    keys_to_dict = {layer_name:1e8 for layer_name in layer_names}\n",
    "    for k in model.keys():\n",
    "        splitted_k = k.split('.')\n",
    "        n_layer = keys_to_dict[splitted_k[0]]\n",
    "        ini_layer = min(n_layer, int(splitted_k[1]))\n",
    "        keys_to_dict[splitted_k[0]] = ini_layer\n",
    "    keys_for_extract = sorted([f'{k}.{v}.{wb}' for (k, v),  wb in product(keys_to_dict.items(), ['weight', 'bias'])])\n",
    "    return {k:v for k, v in model.items() if k in keys_for_extract}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 424/424 [00:23<00:00, 17.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# X, y = [], []\n",
    "left_over_dir = '/scratch/data/TrojAI/rl-lavaworld-jul2023-leftover/models'\n",
    "train_set_dir = '/scratch/data/TrojAI/rl-lavaworld-jul2023-train/models'\n",
    "X, y, X_len = {}, {}, {}\n",
    "for model_num in tqdm(range(238+186)):\n",
    "    model_id = num_to_model_id(model_num)\n",
    "    if model_num >= 238:\n",
    "        model_id = num_to_model_id(model_num-238)\n",
    "        model_dir = left_over_dir\n",
    "    model_dir = train_set_dir\n",
    "    model_filepath = os.path.join(model_dir, model_id, 'model-state-dict.pt')\n",
    "    # model, model_repr, model_class = model_utils.load_model(model_filepath)\n",
    "    model_repr = torch.load(model_filepath)\n",
    "    model_repr = keys_for_extraction(rl_model)\n",
    "    metadata = pd.read_csv(os.path.join(os.path.dirname(model_dir), 'METADATA.csv'))\n",
    "    model_class = metadata[metadata['model_name'] == model_id]['arch'].item()\n",
    "\n",
    "    feature = []\n",
    "    feature += _get_weight_features(model_repr)\n",
    "    feature += _get_eigen_features(model_repr, 20)\n",
    "    # fe, fe_len = _get_weight_features(model_backbone, target_layers=target_weight_layers, normalize=False)\n",
    "    # feature += fe\n",
    "    # if model_arch not in X_len:\n",
    "    #     X_len[model_arch] = eig_len\n",
    "\n",
    "    poisoned = metadata[metadata['model_name'] == model_id]['ground_truth'].item() == 'triggered'\n",
    "\n",
    "    if model_class in X:\n",
    "        X[model_class].append(feature)\n",
    "        y[model_class].append(poisoned)\n",
    "        # X_len[model_class] = fe_len\n",
    "    else:\n",
    "        X[model_class] = [feature]\n",
    "        y[model_class] = [poisoned]\n",
    "        # X_len[model_class] = fe_len\n",
    "\n",
    "    # X.append(feature)\n",
    "    # y.append(poisoned)\n",
    "\n",
    "    # del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3765, 2350)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X['SimplifiedRLStarter'][0]), len(X['BasicFCModel'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSD: (cen array([31,  3, 32, 37, 39, 29, 14,  0, 22, 35]), acc array([31, 37,  3, 42, 25, 39, 32, 45, 29, 19]))\n",
    "DETR: (array([ 80,  55, 134,  52, 285, 321, 267, 320, 299, 305]), array([ 80,  55,  46,  52, 113, 320, 305, 134, 290, 215]))\n",
    "RCNN: (array([147,  12,  18, 164, 161, 169, 114,  72,  45,  53]), array([164, 169, 161, 147,  12,  18, 114, 127, 137, 140]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILEDIR = '/scratch/jialin/rl-lavaworld-jul2023/extracted_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicFCModel 2350\n",
      "SimplifiedRLStarter 3765\n"
     ]
    }
   ],
   "source": [
    "for k, v in X.items():\n",
    "    np.save(os.path.join(OUTPUT_FILEDIR, f'{k}_X_more.npy'), v)\n",
    "    np.save(os.path.join(OUTPUT_FILEDIR, f'{k}_y_more.npy'), y[k])\n",
    "    # np.save(os.path.join(OUTPUT_FILEDIR, f'{k}_X_len.npy'), X_len[k])\n",
    "    print(k, len(v[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:07<00:00,  2.49s/it]\n"
     ]
    }
   ],
   "source": [
    "X_len = {}\n",
    "for model_num in tqdm([0, 1, 3]):\n",
    "    model_id = num_to_model_id(model_num)\n",
    "    model_filepath = os.path.join(MODEL_FILEDIR, model_id, 'model.pt')\n",
    "    model, _, model_class = model_utils.load_model(model_filepath)\n",
    "    model = model.to(device)\n",
    "    if 'Detr' not in model_class:\n",
    "        model_backbone = model.backbone\n",
    "    else:\n",
    "        model_backbone = model\n",
    "\n",
    "    fe_len, idx_list = [], [(0, 1e8)]\n",
    "    # if 'SSD' in model_class:\n",
    "        # idx_list = [(2, 5)]\n",
    "    # elif 'RCNN' in model_class:\n",
    "        # idx_list = [(2, 3)]\n",
    "    # else:\n",
    "        # idx_list = [(45, 45), (69, 69), (79, 79), (89, 89)]\n",
    "            \n",
    "    for idx_lo, idx_hi in idx_list:\n",
    "        fe_len = _get_eigen_vals(model_backbone, idx_lo, idx_hi)[1]\n",
    "    X_len[model_class] = fe_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'FasterRCNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_range = [0] + X_len[key]\n",
    "# weight_range = list(range(0, len(X[key][0])+1, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cens, accs = [], []\n",
    "clf = GradientBoostingClassifier(learning_rate=0.015, n_estimators=900, max_depth=3, max_features= 120, min_samples_leaf= 6, min_samples_split= 24)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def bootstrap_performance(X, y, clf, n=10, test_size=.2, ret_fe_rank = False):\n",
    "    all_cross_entropy, all_accuracy = [], []\n",
    "    if ret_fe_rank:\n",
    "        all_fe_importance = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=i)\n",
    "        \n",
    "        # clf.set_params(random_state=i)            \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        all_cross_entropy.append(log_loss(y_test, clf.predict_proba(X_test), labels=[0, 1]))\n",
    "        all_accuracy.append(clf.score(X_test, y_test))\n",
    "        if ret_fe_rank:\n",
    "            all_fe_importance.append(clf.feature_importances_)\n",
    "    if ret_fe_rank:\n",
    "        return all_cross_entropy, all_accuracy, all_fe_importance\n",
    "    return all_cross_entropy, all_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=1100, learning_rate=0.00225, max_depth=8, min_samples_split=17, subsample=.66, min_samples_leaf=4, max_features=230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = {}, {}\n",
    "for model_class in ['BasicFCModel', 'SimplifiedRLStarter']:\n",
    "    X[model_class] = np.load(os.path.join(OUTPUT_FILEDIR, f'{model_class}_X.npy'))\n",
    "    y[model_class] = np.load(os.path.join(OUTPUT_FILEDIR, f'{model_class}_y.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_inds = json.load(open('/scratch/jialin/rl-lavaworld-jul2023/extracted_features/fe_ind2.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/scratch/data/TrojAI/rl-randomized-lavaworld-aug2023/models/id-00000000/model.pt')\n",
    "rand_fe = _get_eigen_features(model['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_get_weight_features(model['state_dict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_repr = keys_for_extraction(model['state_dict'])\n",
    "rand_fe = []\n",
    "rand_fe += _get_eigen_features(model_repr, ssv_len=20)\n",
    "rand_fe += _get_weight_features(model_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rand_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_repr = keys_for_extraction(rl_model)\n",
    "rand_fe = []\n",
    "rand_fe += _get_eigen_features(model_repr, ssv_len=20)\n",
    "rand_fe += _get_weight_features(model_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rand_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicFCModel 0.6832097431081623 0.5814634146341465\n",
      "SimplifiedRLStarter 0.6927104295683355 0.54\n"
     ]
    }
   ],
   "source": [
    "fe_importance = {}\n",
    "for k, v in X.items():\n",
    "    # cen, acc, fe_rank = bootstrap_performance(v, y[k], clf, n=50, test_size=.2, ret_fe_rank=False)\n",
    "    # print(k, np.mean(cen), np.mean(acc))\n",
    "    # fe_importance[k] = fe_rank\n",
    "    # print(np.argsort(cen)[:10], np.asarray(cen)[np.argsort(cen)[:10]])\n",
    "    # print(np.argsort(acc)[::-1][:10], np.asarray(acc)[np.argsort(acc)[::-1][:10]])\n",
    "    \n",
    "    cen, acc = bootstrap_performance(v, y[k], clf, n=50, test_size=.2, ret_fe_rank=False)\n",
    "    print(k, np.mean(cen), np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X['BasicFCModel'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X['SimplifiedRLStarter'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56115464, 0.43884536]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(np.concatenate([X['BasicFCModel'], X['SimplifiedRLStarter']], axis=0), \n",
    "        np.concatenate([y['BasicFCModel'], y['SimplifiedRLStarter']], axis=0)).predict_proba([rand_fe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/jialin/rl-randomized-lavaworld-aug2023/learned_parameters/clf.joblib']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf.fit(np.concatenate([X['BasicFCModel'], X['SimplifiedRLStarter']], axis=0), \n",
    "        np.concatenate([y['BasicFCModel'], y['SimplifiedRLStarter']], axis=0)), '/scratch/jialin/rl-randomized-lavaworld-aug2023/learned_parameters/clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in X.items():\n",
    "    # v_ind = v[:, fe_inds[k]]\n",
    "    # print(v_ind.shape)\n",
    "    joblib.dump(clf.fit(v, y[k]), os.path.join(OUTPUT_FILEDIR, f'{k}_clf3.joblib'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BasicFCModel 0.1160307642356217 0.9683333333333334\n",
    "SimplifiedRLStarter 0.11422876380716901 0.9758333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAGzCAYAAACM3HvxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABemUlEQVR4nO3dd1gUx/8H8PeBcEcRRJqACKhYsKCiIhp7AWti7JpQrDEaWxITY0FjlGissWsUTew9Go1GUWNU7MFeEcVCEQtNBT3m94c/9ut5hx5yuATer+e55+HmZndml7ndz83OziqEEAJERERE9N4ZyV0BIiIioqKKgRgRERGRTBiIEREREcmEgRgRERGRTBiIEREREcmEgRgRERGRTBiIEREREcmEgRgRERGRTBiIEREREcmEgRgVSO7u7ggODpa7Gjo1adIEVatWNeg6X7x4gZEjR8LV1RVGRkb46KOPDLr+gm758uVQKBS4efOmwdZ54sQJ1K9fHxYWFlAoFIiKijLYuqnguHnzJhQKBZYvX/7eyw4ODoa7u/t7L5cK9jkit/ItEJs/fz4UCgV8fX3zq4hCLSEhAV999RUqVaoEc3NzWFhYwMfHBz/88AMeP34sd/XIwJYtW4affvoJnTt3xooVKzB8+HC5q/Sf9vz5c3Tp0gUPHz7EzJkz8dtvv8HNzQ3z589/7ydsd3d3KBQKna9nz57lS5mTJ0/G1q1b82XdeZWZmYnZs2ejZs2asLKyQokSJVClShX0798fly9flrt6Wu7du4fx48cXyUD+wIEDUCgU2Lhxo9xVybXg4OAcv3evvgwVzK1evRqzZs16p2WLGaQGOqxatQru7u44fvw4rl+/jvLly+dXUYXOiRMn0KZNG6SlpeGTTz6Bj48PAODkyZP48ccfcfDgQfz1118y1zJ/XblyBUZGRafDdt++fXBxccHMmTPlrkqhEB0djVu3bmHJkiXo27evlD5//nzY2dm991/SNWrUwJdffqmVbmpqmi/lTZ48GZ07dy6QPaudOnXCn3/+iR49eqBfv354/vw5Ll++jD/++AP169dHpUqV5K6ihnv37mHChAlwd3dHjRo1ND5bsmQJsrKy5KkYvdGAAQPQokUL6X1MTAzGjRuH/v37o2HDhlJ6uXLlDFLe6tWrcf78eQwbNizXy+ZLIBYTE4MjR45g8+bNGDBgAFatWoXQ0ND8KCrP0tPTYWFhIXc1JI8fP0bHjh1hbGyMf//9V+ugNGnSJCxZskSm2uUvIQSePXsGMzMzKJVKuavzXiUmJqJEiRIGW19WVhYyMzOhUqkMts7/ksTERAAw6D7NyYsXL5CVlfXGoMrFxQWffPJJvtclPxmiTZ04cQJ//PEHJk2ahO+++07js7lz5/7nevtNTEzkrgLlwM/PD35+ftL7kydPYty4cfDz8ytw38V86XJYtWoVbGxs0LZtW3Tu3BmrVq3Sme/x48cYPnw43N3doVQqUbp0aQQGBiIpKUnK8+zZM4wfPx4VKlSASqWCk5MTPv74Y0RHRwP4X9fpgQMHNNata9xAcHAwLC0tER0djTZt2qB48eLo1asXAOCff/5Bly5dUKZMGSiVSri6umL48OF4+vSpVr0vX76Mrl27wt7eHmZmZqhYsSJGjx4NANi/fz8UCgW2bNmitdzq1auhUCgQGRmZ475btGgR7t69ixkzZuj8Zejo6IgxY8ZopM2fPx9VqlSBUqmEs7MzBg0apHVAyx7XdPbsWTRu3Bjm5uYoX7681OX8999/w9fXV9qevXv3aiw/fvx4KBQKadutrKxga2uLoUOHal1eCQ8PR7NmzeDg4AClUgkvLy8sWLBAa1vc3d3Rrl077N69G7Vr14aZmRkWLVokffZqr8Xz588xYcIEeHp6QqVSwdbWFh988AH27Nmjsc59+/ahYcOGsLCwQIkSJfDhhx/i0qVLOrfl+vXrCA4ORokSJWBtbY2QkBA8efJEx39Ft1OnTqF+/fowMzODh4cHFi5cqJUnIyMDoaGhKF++vNSuRo4ciYyMDAD/a6f79+/HhQsXpO7y7Pacnp6OL7/8Eq6urlAqlahYsSKmTZsGIYRGOQqFAoMHD8aqVauktrBr1y4AwN27d9G7d284OjpCqVSiSpUqWLZsmV7bmNv/5aFDh1C3bl2oVCqULVsWv/76q1beCxcuoFmzZjAzM0Pp0qXxww8/6N2rcPbsWQQHB6Ns2bJQqVQoVaoUevfujQcPHkh5goOD0bhxYwBAly5doFAo0KRJE7i7u+PChQv4+++/pf3cpEkTabnHjx9j2LBh0r4uX748pkyZolG37P/XtGnTMGvWLJQrVw5KpRIXL17Uq/450adsAJg2bRrq168PW1tbmJmZwcfHR+uykUKhQHp6OlasWKF1+SWnMU3Z34nX12PoNpV93G7QoIHWZ8bGxrC1tdVIy0vbvXz5Mjp37oySJUtCpVKhdu3a2LZtm1a+N52HDhw4gDp16gAAQkJCpP2ZfV7RtT9z+53dunUrqlatKm1f9j5+m8TERPTp0weOjo5QqVTw9vbGihUrNPK82l4XL14stdc6dergxIkTepWjjxs3bqBLly4oWbIkzM3NUa9ePezYsUMr39vO54B+bdyQjh07hoCAAFhbW8Pc3ByNGzfG4cOHNfKkpqZi2LBhUhtxcHBAy5Ytcfr0aQAvz687duzArVu3pDaSm7GD+dIjtmrVKnz88ccwNTVFjx49sGDBApw4cUJq0ACQlpaGhg0b4tKlS+jduzdq1aqFpKQkbNu2DXfu3IGdnR3UajXatWuHiIgIdO/eHUOHDkVqair27NmD8+fPv1OX4osXL+Dv748PPvgA06ZNg7m5OQBgw4YNePLkCQYOHAhbW1scP34cc+bMwZ07d7BhwwZp+bNnz6Jhw4YwMTFB//794e7ujujoaGzfvh2TJk1CkyZN4OrqilWrVqFjx45a+6VcuXIaUfrrtm3bBjMzM3Tu3Fmv7Rk/fjwmTJiAFi1aYODAgbhy5Yq0vw8fPqzxi+3Ro0do164dunfvji5dumDBggXo3r07Vq1ahWHDhuGzzz5Dz549pbFKt2/fRvHixTXK69q1K9zd3REWFoajR4/i559/xqNHjzROuAsWLECVKlXQoUMHFCtWDNu3b8fnn3+OrKwsDBo0SGN9V65cQY8ePTBgwAD069cPFStWzHE7w8LC0LdvX9StWxcpKSk4efIkTp8+jZYtWwIA9u7di9atW6Ns2bIYP348nj59ijlz5qBBgwY4ffq01heja9eu8PDwQFhYGE6fPo1ffvkFDg4OmDJlylv3+6NHj9CmTRt07doVPXr0wPr16zFw4ECYmpqid+/eAF72IHTo0AGHDh1C//79UblyZZw7dw4zZ87E1atXsXXrVtjb2+O3337DpEmTkJaWhrCwMABA5cqVIYRAhw4dsH//fvTp0wc1atTA7t278fXXX+Pu3btalzH37duH9evXY/DgwbCzs4O7uzsSEhJQr1496aBvb2+PP//8E3369EFKSspbu9Fz87+8fv06OnfujD59+iAoKAjLli1DcHAwfHx8UKVKFQBAfHw8mjZtihcvXuDbb7+FhYUFFi9eDDMzs7fucwDYs2cPbty4gZCQEJQqVQoXLlzA4sWLceHCBRw9ehQKhQIDBgyAi4sLJk+ejCFDhqBOnTpwdHREeno6vvjiC1haWko/nBwdHQEAT548QePGjXH37l0MGDAAZcqUwZEjRzBq1CjExcVpjf0IDw/Hs2fP0L9/fyiVSpQsWfKN9X7+/LnGD0wAMDc3h7m5ea7Knj17Njp06IBevXohMzMTa9euRZcuXfDHH3+gbdu2AIDffvtN+p70798fwLtffjF0m3JzcwPw8ljYoEEDFCuW8ykoL+VcuHABDRo0gIuLi9TO1q9fj48++gibNm2Sjs1vOw9VrlwZ33//vdYlrfr16+ssN7ff2UOHDmHz5s34/PPPUbx4cfz888/o1KkTYmNjtYLSVz19+hRNmjTB9evXMXjwYHh4eGDDhg0IDg7G48ePMXToUI38q1evRmpqKgYMGACFQoGpU6fi448/xo0bN/Lcq5eQkID69evjyZMnGDJkCGxtbbFixQp06NABGzdulPa1vudzfdq4oezbtw+tW7eGj48PQkNDYWRkJP34/Oeff1C3bl0AwGeffYaNGzdi8ODB8PLywoMHD3Do0CFcunQJtWrVwujRo5GcnIw7d+5I/2NLS0v9KyIM7OTJkwKA2LNnjxBCiKysLFG6dGkxdOhQjXzjxo0TAMTmzZu11pGVlSWEEGLZsmUCgJgxY0aOefbv3y8AiP3792t8HhMTIwCI8PBwKS0oKEgAEN9++63W+p48eaKVFhYWJhQKhbh165aU1qhRI1G8eHGNtFfrI4QQo0aNEkqlUjx+/FhKS0xMFMWKFROhoaFa5bzKxsZGeHt7vzHPq+s0NTUVrVq1Emq1WkqfO3euACCWLVsmpTVu3FgAEKtXr5bSLl++LAAIIyMjcfToUSl99+7dWvsuNDRUABAdOnTQqMPnn38uAIgzZ85Iabr2pb+/vyhbtqxGmpubmwAgdu3apZXfzc1NBAUFSe+9vb1F27Zt37A3hKhRo4ZwcHAQDx48kNLOnDkjjIyMRGBgoNa29O7dW2P5jh07Cltb2zeWIcT/9uX06dOltIyMDKn8zMxMIYQQv/32mzAyMhL//POPxvILFy4UAMThw4c11lmlShWNfFu3bhUAxA8//KCR3rlzZ6FQKMT169eltOz/44ULFzTy9unTRzg5OYmkpCSN9O7duwtra2ud/6tX5fZ/efDgQSktMTFRKJVK8eWXX0ppw4YNEwDEsWPHNPJZW1sLACImJibX9VmzZo1W2dnHhQ0bNmjkrVKlimjcuLHWOiZOnCgsLCzE1atXNdK//fZbYWxsLGJjY4UQ/zuuWFlZicTExDfWNVv2vnn9lX0s0LdsXdufmZkpqlatKpo1a6aRbmFhofH9yRYUFCTc3Ny00rO/E6/KjzaVlZUlfX8cHR1Fjx49xLx587SOp7kpR9exvnnz5qJatWri2bNnGmXXr19feHp6Smn6nIdOnDihtf5sr+/P3H5nTU1NNdLOnDkjAIg5c+ZolfWqWbNmCQBi5cqVUlpmZqbw8/MTlpaWIiUlRWPf2NraiocPH0p5f//9dwFAbN++/Y3l5PQ9elX2d/rV41xqaqrw8PAQ7u7u0rlJn/O5EPq38dfPEW/z+v8xKytLeHp6Cn9/f63yPTw8RMuWLaU0a2trMWjQoDeuv23btjq/W/ow+KXJVatWwdHREU2bNgXwsvu1W7duWLt2LdRqtZRv06ZN8Pb21uo1yl4mO4+dnR2++OKLHPO8i4EDB2qlvfqLPD09HUlJSahfvz6EEPj3338BAPfv38fBgwfRu3dvlClTJsf6BAYGIiMjQ6M7dd26dXjx4sVbr02npKRo9ULlZO/evcjMzMSwYcM0Brb369cPVlZWWl3DlpaW6N69u/S+YsWKKFGiBCpXrqxxd2v23zdu3NAq8/VekOz/zc6dO6W0V/dlcnIykpKS0LhxY9y4cQPJyckay3t4eMDf3/+t21qiRAlcuHAB165d0/l5XFwcoqKiEBwcrNE7Ub16dbRs2VKjftk+++wzjfcNGzbEgwcPkJKS8tb6FCtWDAMGDJDem5qaYsCAAUhMTMSpU6cAvOxlrVy5MipVqoSkpCTp1axZMwAvL2O/yc6dO2FsbIwhQ4ZopH/55ZcQQuDPP//USG/cuDG8vLyk90IIbNq0Ce3bt4cQQqMO/v7+SE5OlrrWc5Kb/6WXl5fGIFh7e3tUrFhRox3t3LkT9erVk35pZufLHiLwNq/W59mzZ0hKSkK9evUA4K3b8iYbNmxAw4YNYWNjo7GfWrRoAbVajYMHD2rk79SpE+zt7fVev6+vL/bs2aPxCgwMzHXZr27/o0ePkJycjIYNG+Zp29/E0G1KoVBg9+7d+OGHH2BjY4M1a9Zg0KBBcHNzQ7du3aQhFXkp5+HDh9i3bx+6du2K1NRUabkHDx7A398f165dw927dwHodx7Kjdx+Z1u0aKHRW1m9enVYWVnpPPa+Xk6pUqXQo0cPKc3ExARDhgxBWloa/v77b4383bp1g42NjfQ++3v6tnL0sXPnTtStWxcffPCBlGZpaYn+/fvj5s2b0mV7fc/n76uNR0VF4dq1a+jZsycePHggtZP09HQ0b94cBw8elIYGlChRAseOHcO9e/cMWodsBr00qVarsXbtWjRt2hQxMTFSuq+vL6ZPn46IiAi0atUKwMuxAp06dXrj+qKjo1GxYsU3dl/nVrFixVC6dGmt9NjYWIwbNw7btm3Do0ePND7LPuFkN9q3zSFVqVIl1KlTB6tWrUKfPn0AvAxQ69Wr99a7R62srJCamqrXtty6dQsAtC7nmZqaomzZstLn2UqXLq11cLG2toarq6tWGgCt/QAAnp6eGu/LlSsHIyMjjfmfDh8+jNDQUERGRmqNuUpOTpbWD7wMxPTx/fff48MPP0SFChVQtWpVBAQE4NNPP0X16tUB5LwvgJeX+Xbv3q11Y8brwXT2gerRo0ewsrJ6Y32cnZ21bvKoUKECgJfjMurVq4dr167h0qVLOZ6wsweU5+TWrVtwdnbWCswrV64sff6q1/fl/fv38fjxYyxevBiLFy9+pzrk5n/5+v4EXu7TV9vRrVu3dE5pk9Ml6dc9fPgQEyZMwNq1a7Xq/npgmBvXrl3D2bNn9f5f6dtus9nZ2WncwfWuZf/xxx/44YcfEBUVJY0zBPL2w/RN8qNNKZVKjB49GqNHj0ZcXBz+/vtvzJ49G+vXr4eJiQlWrlyZp3KuX78OIQTGjh2LsWPH5risi4uLXueh3Mjtd1af70xO5Xh6emrdWa5vOa8e6/Iqp+/0q3WpWrWq3ufz99XGs3/UBwUF5ZgnOTkZNjY2mDp1KoKCguDq6gofHx+0adMGgYGBKFu2rEHqYtBAbN++fYiLi8PatWuxdu1arc9XrVolBWKGktM/59Xet1cplUqtxqtWq9GyZUs8fPgQ33zzDSpVqgQLCwvcvXsXwcHB73R7cmBgIIYOHYo7d+4gIyMDR48exdy5c9+6XKVKlRAVFYXMzEyD39pubGycq3Tx2uBSXV7f/9HR0WjevDkqVaqEGTNmwNXVFaampti5cydmzpyptS/1HRvUqFEjREdH4/fff8dff/2FX375BTNnzsTChQs1pifIjbxstz6ysrJQrVo1zJgxQ+fnrwfAefX6vsze15988kmOB5vsQFaX3P4v83t/Ai/H9R05cgRff/01atSoAUtLS2RlZSEgICBP0whkZWWhZcuWGDlypM7Ps4PsbPq2W0OW/c8//6BDhw5o1KgR5s+fDycnJ5iYmCA8PByrV6/Wq6zcHi8N3aZe5+TkhO7du6NTp06oUqUK1q9fj+XLl+epnOxlv/rqqxx72wvKdErv4zvzPsvJK0O0cX1lt5OffvpJa1qSbNnjvLp27YqGDRtiy5Yt+Ouvv/DTTz9hypQp2Lx5M1q3bp3nuhg0EFu1ahUcHBwwb948rc82b96MLVu2YOHChTAzM0O5cuVw/vz5N66vXLlyOHbsGJ4/f57jgMLsyP71uwRf/0XwJufOncPVq1exYsUK6XIBAK078rKj37fVGwC6d++OESNGYM2aNXj69ClMTEzQrVu3ty7Xvn17REZGYtOmTRrdzrpkD3y9cuWKRmSemZmJmJiYHH+B58W1a9c0fiVfv34dWVlZ0kD47du3IyMjA9u2bdP4Ffa2y3D6KFmyJEJCQhASEoK0tDQ0atQI48ePR9++fTX2xesuX74MOzs7g05Tcu/ePa0etqtXrwKAtC/KlSuHM2fOoHnz5u/0a87NzQ179+5Famqqxi/s7Ekvs7c5J/b29ihevDjUavU7tYX8+F+6ubnpvLys6//2ukePHiEiIgITJkzAuHHjpPScLlfrktP/oVy5ckhLS8uX78zb6Fv2pk2boFKpsHv3bo3pXcLDw7Xy5rSdNjY2OqeI0Pd4mdc2lRMTExNUr14d165dQ1JSUp7KyT4WmpiYvHVZfc5Dufnu5vU7m5tyzp49i6ysLI2OBUOXo29dcjruvloXfc7nuWnjeZV9SdjKykqvNubk5ITPP/8cn3/+ORITE1GrVi1MmjRJCsTy0mNnsDFiT58+xebNm9GuXTt07txZ6zV48GCkpqZKtw936tQJZ86c0TnNQ3aU3qlTJyQlJensScrO4+bmBmNjY60xHPPnz9e77tm/Fl79dSCEwOzZszXy2dvbo1GjRli2bBliY2N11iebnZ0dWrdujZUrV2LVqlUICAiAnZ3dW+vy2WefwcnJCV9++aV0Yn9VYmIifvjhBwAvxxeYmpri559/1ih/6dKlSE5ONvgdJgC0guw5c+YAgNQYde3L5OTkPH+RXp2eAHj5S6V8+fJS17WTkxNq1KiBFStWaJxozp8/j7/++gtt2rTJU/mve/HihTTVBvAy+F20aBHs7e2lCXi7du2Ku3fv6pz37enTp0hPT39jGW3atIFardZq/zNnzoRCoXjrLzFjY2N06tQJmzZt0nmyuX///luXBwz7v2zTpg2OHj2K48ePa9Qjpylu3lYfALmazdrCwkJnINK1a1dERkZi9+7dWp89fvwYL1680LuM3NK3bGNjYygUCo3eq5s3b+qcQT+n7SxXrhySk5Nx9uxZKS0uLk7ncViXvLapa9euaR07gZfbGRkZCRsbG9jb2+epHAcHBzRp0gSLFi1CXFzcG5fV5zyU/WNLnznO8vqd1VebNm0QHx+PdevWSWkvXrzAnDlzYGlpKU3f8j60adMGx48f15iWKT09HYsXL4a7u7s0xlCf83lu2nhe+fj4oFy5cpg2bRrS0tK0Ps9uJ2q1WmvYg4ODA5ydnTUunVpYWLzz8AiD9Yht27YNqamp6NChg87P69WrB3t7e6xatQrdunXD119/jY0bN6JLly7o3bs3fHx88PDhQ2zbtg0LFy6Et7c3AgMD8euvv2LEiBE4fvw4GjZsiPT0dOzduxeff/45PvzwQ1hbW6NLly6YM2cOFAoFypUrhz/++OOt4xReValSJZQrVw5fffUV7t69CysrK2zatEnn9fOff/4ZH3zwAWrVqoX+/fvDw8MDN2/exI4dO7QegREYGChNQzFx4kS96mJjY4MtW7agTZs2qFGjhsbM+qdPn8aaNWuk6S/s7e0xatQoTJgwAQEBAejQoQOuXLmC+fPno06dOvkyaV1MTAw6dOiAgIAAREZGYuXKlejZsye8vb0BAK1atYKpqSnat2+PAQMGIC0tDUuWLIGDg4POg6K+vLy80KRJE/j4+KBkyZI4efKkdDtxtp9++gmtW7eGn58f+vTpI01fYW1tjfHjx+d10zU4OztjypQpuHnzJipUqIB169YhKioKixcvln7tffrpp1i/fj0+++wz7N+/Hw0aNIBarcbly5exfv16af60nLRv3x5NmzbF6NGjcfPmTXh7e+Ovv/7C77//jmHDhuk1JcGPP/6I/fv3w9fXF/369YOXlxcePnyI06dPY+/evXj48GGOy+bH/3LkyJH47bffEBAQgKFDh0rTV2T/wn8TKysrNGrUCFOnTsXz58/h4uKCv/76S2M86tv4+PhgwYIF+OGHH1C+fHk4ODigWbNm+Prrr7Ft2za0a9dOmnIjPT0d586dw8aNG3Hz5k29fki9C33Lbtu2LWbMmIGAgAD07NkTiYmJmDdvHsqXL6+173x8fLB3717MmDEDzs7O8PDwgK+vL7p3745vvvkGHTt2xJAhQ/DkyRMsWLAAFSpU0HswdF7a1JkzZ9CzZ0+0bt0aDRs2RMmSJXH37l2sWLEC9+7dw6xZs6SAOy/lzJs3Dx988AGqVauGfv36oWzZskhISEBkZCTu3LmDM2fOSPv+beehcuXKoUSJEli4cCGKFy8OCwsL+Pr66hwnaIjvrD769++PRYsWITg4GKdOnYK7uzs2btyIw4cPY9asWXrf8KWvTZs26Xz8VFBQEL799lusWbMGrVu3xpAhQ1CyZEmsWLECMTEx2LRpk9Rjp8/5PDdtPK+MjIzwyy+/oHXr1qhSpQpCQkLg4uKCu3fvYv/+/bCyssL27duRmpqK0qVLo3PnzvD29oalpSX27t2LEydOYPr06dL6fHx8sG7dOowYMQJ16tSBpaUl2rdvr19l3uleSx3at28vVCqVSE9PzzFPcHCwMDExkW5HfvDggRg8eLBwcXERpqamonTp0iIoKEjjduUnT56I0aNHCw8PD2FiYiJKlSolOnfuLKKjo6U89+/fF506dRLm5ubCxsZGDBgwQJw/f17n9BUWFhY663bx4kXRokULYWlpKezs7ES/fv2kW4lfv235/PnzomPHjqJEiRJCpVKJihUrirFjx2qtMyMjQ9jY2Ahra2vx9OlTfXaj5N69e2L48OGiQoUKQqVSCXNzc+Hj4yMmTZokkpOTNfLOnTtXVKpUSZiYmAhHR0cxcOBA8ejRI408uqZHEOLlLcC6poUAoHG7bvbt7RcvXhSdO3cWxYsXFzY2NmLw4MFa27Zt2zZRvXp1oVKphLu7u5gyZYp06/Kr0xPkVHb2Z6/emvzDDz+IunXrihIlSggzMzNRqVIlMWnSJGmqiGx79+4VDRo0EGZmZsLKykq0b99eXLx4USNP9rbcv39fIz08PFyvKRSy9+XJkyeFn5+fUKlUws3NTcydO1crb2ZmppgyZYqoUqWKUCqVwsbGRvj4+IgJEyZo/B9z+v+kpqaK4cOHC2dnZ2FiYiI8PT3FTz/9pHG7tRDa/69XJSQkiEGDBglXV1fpO9S8eXOxePHiN26nEHn/XzZu3FhruoizZ8+Kxo0bC5VKJVxcXMTEiRPF0qVL9dr3d+7ckb571tbWokuXLuLevXsa00EIkfNt9/Hx8aJt27aiePHiAoBG3VJTU8WoUaNE+fLlhampqbCzsxP169cX06ZNk9pZ9nQAP/3001v33dv2zav0KVsIIZYuXSo8PT2FUqkUlSpVEuHh4Tqnnrh8+bJo1KiRMDMzEwA0vkt//fWXqFq1qjA1NRUVK1YUK1euzHH6CkO3qYSEBPHjjz+Kxo0bCycnJ1GsWDFhY2MjmjVrJjZu3PhO5eiavkIIIaKjo0VgYKAoVaqUMDExES4uLqJdu3Za5ehzHvr999+Fl5eXKFasmEZZuqYDyet3Vt9pGRISEkRISIiws7MTpqamolq1alr74E3t9fXvjC7Z36OcXtlTVkRHR4vOnTtL58S6deuKP/74Q2t9+pzP9W3jeZ2+Itu///4rPv74Y2FrayuUSqVwc3MTXbt2FREREUKIl+fxr7/+Wnh7e4vixYsLCwsL4e3tLebPn6+xnrS0NNGzZ09RokQJASBXU1kohChgo/UKkRcvXsDZ2Rnt27fH0qVL5a5OnmRPHHv//v186xkgIiIqaorOU5VlsHXrVty/f1/jBgAiIiKibPnyiKOi7tixYzh79iwmTpyImjVrvteBk0RERPTfwR6xfLBgwQIMHDgQDg4OOh96TERERAQAHCNGREREJBP2iBERERHJhIEYERERkUyK3GD9rKws3Lt3D8WLF8+3B+USERGRYQkhkJqaCmdnZ61nRv+XFblA7N69ewZ/2DIRERG9H7dv30bp0qXlrobBFLlALPvRD7dv34aVlZXMtSEiIiJ9pKSkwNXV1eCPcJJbkQvEsi9HWllZMRAjIiL6jylsw4oKz0VWIiIiov8YBmJEREREMpE1EDt48CDat28PZ2dnKBQKbN269a3LHDhwALVq1YJSqUT58uWxfPnyfK8nERERUX6QNRBLT0+Ht7c35s2bp1f+mJgYtG3bFk2bNkVUVBSGDRuGvn37Yvfu3flcUyIiooJj3rx5cHd3h0qlgq+vL44fP55j3ufPn+P7779HuXLloFKp4O3tjV27dmnkcXd3h0Kh0HoNGjRII19kZCSaNWsGCwsLWFlZoVGjRnj69Gm+bGNRIetg/datW6N169Z651+4cCE8PDwwffp0AEDlypVx6NAhzJw5E/7+/vlVTSIiogJj3bp1GDFiBBYuXAhfX1/MmjUL/v7+uHLlChwcHLTyjxkzBitXrsSSJUtQqVIl7N69Gx07dsSRI0dQs2ZNAMCJEyegVqulZc6fP4+WLVuiS5cuUlpkZCQCAgIwatQozJkzB8WKFcOZM2cK1ZxeshAFBACxZcuWN+Zp2LChGDp0qEbasmXLhJWVVY7LPHv2TCQnJ0uv27dvCwAiOTnZALU2jLlz5wo3NzehVCpF3bp1xbFjx3LMm5mZKSZMmCDKli0rlEqlqF69uvjzzz818ri5uQkAWq/PP/88vzeFiPLB+z5GPHjwQAwePFhUqFBBqFQq4erqKr744gvx+PHjfN1O0k/dunXFoEGDpPdqtVo4OzuLsLAwnfmdnJzE3LlzNdI+/vhj0atXrxzLGDp0qChXrpzIysqS0nx9fcWYMWPyWPt3l5ycXODO34bwnwpj4+Pj4ejoqJHm6OiIlJSUHLtGw8LCYG1tLb0K2mSu2b9sQkNDcfr0aXh7e8Pf3x+JiYk6848ZMwaLFi3CnDlzcPHiRXz22Wfo2LEj/v33XynPiRMnEBcXJ7327NkDABq/bKjgMvQlBwC4e/cuPvnkE9ja2sLMzAzVqlXDyZMnpc/T0tIwePBglC5dGmZmZvDy8sLChQvzZfsod+Q4Rty7dw/37t3DtGnTcP78eSxfvhy7du1Cnz598n+D6Y0yMzNx6tQptGjRQkozMjJCixYtEBkZqXOZjIwMqFQqjTQzMzMcOnQoxzJWrlyJ3r17S1NFJCYm4tixY3BwcED9+vXh6OiIxo0b57gOygW5I8Fs0KNHzNPTU0yePFkjbceOHQKAePLkic5lCnqPmFy/bKhgWrt2rTA1NRXLli0TFy5cEP369RMlSpQQCQkJOvOPHDlSODs7ix07dojo6Ggxf/58oVKpxOnTp6U8Dx8+FG5ubiI4OFgcO3ZM3LhxQ+zevVtcv35dytOvXz9Rrlw5sX//fhETEyMWLVokjI2Nxe+//57v20xvVlCOEevXrxempqbi+fPnudwCMqS7d+8KAOLIkSMa6V9//bWoW7euzmV69OghvLy8xNWrV4VarRZ//fWXMDMzE6ampjrzr1u3ThgbG4u7d+9KaZGRkQKAKFmypFi2bJk4ffq0GDZsmDA1NRVXr1413Aa+AXvECoBSpUohISFBIy0hIQFWVlYwMzPTuYxSqZQmby1ok7jK9cuGCq4ZM2agX79+CAkJkXqlzM3NsWzZMp35f/vtN3z33Xdo06YNypYti4EDB6JNmzbSOEoAmDJlClxdXREeHo66devCw8MDrVq1Qrly5aQ8R44cQVBQEJo0aQJ3d3f0798f3t7eb+yNo/xXkI4RycnJsLKyQrFiRW4e8P+82bNnw9PTE5UqVYKpqSkGDx6MkJCQHMd2LV26FK1bt4azs7OUlpWVBQAYMGAAQkJCULNmTcycORMVK1bM8fhE+vlPBWJ+fn6IiIjQSNuzZw/8/PxkqlHeJCUlQa1W67zcGh8fr3MZf39/zJgxA9euXUNWVhb27NmDzZs3Iy4uTmf+rVu34vHjxwgODjZ09cnA8uuku23bNtSuXRtdunSBg4MDatasiSVLlmgsU79+fWzbtg13796FEAL79+/H1atX0apVKwNuIeVWQTlGJCUlYeLEiejfv/87bwsZhp2dHYyNjXV2SpQqVUrnMvb29ti6dSvS09Nx69YtXL58GZaWlihbtqxW3lu3bmHv3r3o27evRrqTkxMAwMvLSyO9cuXKiI2NzcsmFXmyBmJpaWmIiopCVFQUgJfTU0RFRUn/1FGjRiEwMFDK/9lnn+HGjRsYOXIkLl++jPnz52P9+vUYPny4HNWXhSF+2VDBlF8n3Rs3bmDBggXw9PTE7t27MXDgQAwZMgQrVqyQ8syZMwdeXl4oXbo0TE1NERAQgHnz5qFRo0b5s7GUbwx9jEhJSUHbtm3h5eWF8ePH52PNSR+mpqbw8fHR6JTIyspCRETEWzslVCoVXFxc8OLFC2zatAkffvihVp7w8HA4ODigbdu2Gunu7u5wdnbGlStXNNKvXr0KNze3PGwRyTpGbP/+/Trv3AkKChJCCBEUFCQaN26stUyNGjWEqampKFu2rAgPD89VmQXpGnNGRoYwNjbWGhsXGBgoOnTo8MZlnz59Ku7cuSOysrLEyJEjhZeXl1aemzdvCiMjI7F161ZDVpvyybuM/UhMTBQffvihMDIyEsbGxqJChQri888/FyqVSspjYmIi/Pz8NJb74osvRL169aT3P/30k6hQoYLYtm2bOHPmjJgzZ46wtLQUe/bsMeAWUm7JfYxISUkRfn5+onnz5uLp06fvvB1kWGvXrhVKpVIsX75cXLx4UfTv31+UKFFCxMfHCyGE+PTTT8W3334r5T969KjYtGmTiI6OFgcPHhTNmjUTHh4e4tGjRxrrVavVokyZMuKbb77RWe7MmTOFlZWV2LBhg7h27ZoYM2aMUKlUGuNN81NBOn8bUoEZrP++FLR/ZN26dcXgwYOl92q1Wri4uOQ4EPd1mZmZoly5cmLUqFFan4WGhopSpUpxcO1/RH6ddMuUKSP69OmjkX/+/PnC2dlZCCHEkydPhImJifjjjz808vTp00f4+/vnYYvIEOQ6RiQnJ4t69eqJxo0bi/T09HffAMoXc+bMEWXKlBGmpqaibt264ujRo9JnjRs3ljo0hBDiwIEDonLlykKpVApbW1vx6aefagzEz7Z7924BQFy5ciXHcsPCwkTp0qWFubm58PPzE//8849Bt+tNCtr521AYiMlMrl82VDDlx0m3R48e4oMPPtDIN2zYMKmXLPs7sXPnTo08/fv3Fy1btnzXTSEDkeMYkZycLHx9fUW1atXE9evXRVxcnPR68eJFvm4vUU4K2vnbUBiIFQBy/bKhgic/TrrHjx8XxYoVE5MmTRLXrl0Tq1atEubm5mLlypVSnsaNG4sqVaqI/fv3ixs3bojw8HChUqnE/Pnz39u2U87e9zEip2EjAERMTEx+bGLRBhS+Vz4oiOdvQ2AgRlTA5MdJd/v27aJq1apCqVSKSpUqicWLF2t8HhcXJ4KDg4Wzs7NQqVSiYsWKYvr06Zx7juh9kDtoYiAmK4UQQryvGwMKgpSUFFhbW0tz4hhaYZyqq2i1EKL8xWMEaWGj0Et+n7/lwpn5iPITD7BERPQG/6kJXYmIiIgKEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDJhIEZEREQkEwZiRERERDKRPRCbN28e3N3doVKp4Ovri+PHj78x/6xZs1CxYkWYmZnB1dUVw4cPx7Nnz95TbYmIiIgMR9ZAbN26dRgxYgRCQ0Nx+vRpeHt7w9/fH4mJiTrzr169Gt9++y1CQ0Nx6dIlLF26FOvWrcN33333nmtORERElHeyBmIzZsxAv379EBISAi8vLyxcuBDm5uZYtmyZzvxHjhxBgwYN0LNnT7i7u6NVq1bo0aPHW3vRiIiIiAoi2QKxzMxMnDp1Ci1atPhfZYyM0KJFC0RGRupcpn79+jh16pQUeN24cQM7d+5EmzZtciwnIyMDKSkpGi8iIiKigqCYXAUnJSVBrVbD0dFRI93R0RGXL1/WuUzPnj2RlJSEDz74AEIIvHjxAp999tkbL02GhYVhwoQJBq07ERERkSHIPlg/Nw4cOIDJkydj/vz5OH36NDZv3owdO3Zg4sSJOS4zatQoJCcnS6/bt2+/xxoTERER5Uy2HjE7OzsYGxsjISFBIz0hIQGlSpXSuczYsWPx6aefom/fvgCAatWqIT09Hf3798fo0aNhZKQdVyqVSiiVSsNvABEREVEeydYjZmpqCh8fH0REREhpWVlZiIiIgJ+fn85lnjx5ohVsGRsbAwCEEPlXWSIiIqJ8IFuPGACMGDECQUFBqF27NurWrYtZs2YhPT0dISEhAIDAwEC4uLggLCwMANC+fXvMmDEDNWvWhK+vL65fv46xY8eiffv2UkBGRERE9F8hayDWrVs33L9/H+PGjUN8fDxq1KiBXbt2SQP4Y2NjNXrAxowZA4VCgTFjxuDu3buwt7dH+/btMWnSJLk2gYiIiOidKUQRu6aXkpICa2trJCcnw8rKyuDrVygMvkrZFa0WYmBsEPQaNgnSwkahl/w+f8vlP3XXJBEREVFhwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkwkCMiIiISCYMxIiIiIhkInsgNm/ePLi7u0OlUsHX1xfHjx9/Y/7Hjx9j0KBBcHJyglKpRIUKFbBz5873VFsiIiIiwykmZ+Hr1q3DiBEjsHDhQvj6+mLWrFnw9/fHlStX4ODgoJU/MzMTLVu2hIODAzZu3AgXFxfcunULJUqUeP+VJyIiIsojhRBCyFW4r68v6tSpg7lz5wIAsrKy4Orqii+++ALffvutVv6FCxfip59+wuXLl2FiYvJOZaakpMDa2hrJycmwsrLKU/11USgMvkrZyddCCgE2CHoNmwRpYaPQS36fv+Ui26XJzMxMnDp1Ci1atPhfZYyM0KJFC0RGRupcZtu2bfDz88OgQYPg6OiIqlWrYvLkyVCr1TmWk5GRgZSUFI0XERERUUEgWyCWlJQEtVoNR0dHjXRHR0fEx8frXObGjRvYuHEj1Go1du7cibFjx2L69On44YcfciwnLCwM1tbW0svV1dWg20FERET0rmQfrJ8bWVlZcHBwwOLFi+Hj44Nu3bph9OjRWLhwYY7LjBo1CsnJydLr9u3b77HGRERERDmTbbC+nZ0djI2NkZCQoJGekJCAUqVK6VzGyckJJiYmMDY2ltIqV66M+Ph4ZGZmwtTUVGsZpVIJpVJp2MoTERERGUCue8Tc3d3x/fffIzY2Nk8Fm5qawsfHBxEREVJaVlYWIiIi4Ofnp3OZBg0a4Pr168jKypLSrl69CicnJ51BGBEREVFBlutAbNiwYdi8eTPKli2Lli1bYu3atcjIyHinwkeMGIElS5ZgxYoVuHTpEgYOHIj09HSEhIQAAAIDAzFq1Cgp/8CBA/Hw4UMMHToUV69exY4dOzB58mQMGjTonconIiIiktM7BWJRUVE4fvw4KleujC+++AJOTk4YPHgwTp8+nat1devWDdOmTcO4ceNQo0YNREVFYdeuXdIA/tjYWMTFxUn5XV1dsXv3bpw4cQLVq1fHkCFDMHToUJ1TXRAREREVdHmeR+z58+eYP38+vvnmGzx//hzVqlXDkCFDEBISAkUBnBuF84jlHucIygM2CHoNmwRpYaPQS2GdR+ydB+s/f/4cW7ZsQXh4OPbs2YN69eqhT58+uHPnDr777jvs3bsXq1evNmRdiYiIiAqVXAdip0+fRnh4ONasWQMjIyMEBgZi5syZqFSpkpSnY8eOqFOnjkErSkRERFTY5DoQq1OnDlq2bIkFCxbgo48+0vmoIQ8PD3Tv3t0gFSQiIiIqrHIdiN24cQNubm5vzGNhYYHw8PB3rhQRERFRUZDruyYTExNx7NgxrfRjx47h5MmTBqkUERERUVGQ60Bs0KBBOh8TdPfuXc7nRURERJQLuQ7ELl68iFq1amml16xZExcvXjRIpYiIiIiKglwHYkqlUuv5kAAQFxeHYsVke3QlERER0X9OrgOxVq1aYdSoUUhOTpbSHj9+jO+++w4tW7Y0aOWIiIiICrNcd2FNmzYNjRo1gpubG2rWrAkAiIqKgqOjI3777TeDV5CIiIiosMp1IObi4oKzZ89i1apVOHPmDMzMzBASEoIePXronFOMiIiIiHR7p0FdFhYW6N+/v6HrQkRERFSkvPPo+osXLyI2NhaZmZka6R06dMhzpYiIiIiKgneaWb9jx444d+4cFAoFxP8/YV3x/0+PV6vVhq0hERERUSGV67smhw4dCg8PDyQmJsLc3BwXLlzAwYMHUbt2bRw4cCAfqkhERERUOOW6RywyMhL79u2DnZ0djIyMYGRkhA8++ABhYWEYMmQI/v333/yoJxEREVGhk+seMbVajeLFiwMA7OzscO/ePQCAm5sbrly5YtjaERERERViue4Rq1q1Ks6cOQMPDw/4+vpi6tSpMDU1xeLFi1G2bNn8qCMRERFRoZTrQGzMmDFIT08HAHz//fdo164dGjZsCFtbW6xbt87gFSQiIiIqrBQi+7bHPHj48CFsbGykOycLspSUFFhbWyM5ORlWVlYGX/9/YBfkWt5bSBHGBkGvYZMgLWwUesnv87dccjVG7Pnz5yhWrBjOnz+vkV6yZMn/RBBGREREVJDkKhAzMTFBmTJlOFcYERERkQHk+q7J0aNH47vvvsPDhw/zoz5ERERERUauB+vPnTsX169fh7OzM9zc3GBhYaHx+enTpw1WOSIiIqLCLNeB2EcffZQP1SAiIiIqegxy1+R/Ce+azL2i1UIMjA2CXsMmQVrYKPTCuyaJiIiIyKByfWnSyMjojVNV8I5KIiIiIv3kOhDbsmWLxvvnz5/j33//xYoVKzBhwgSDVYyIiIiosDPYGLHVq1dj3bp1+P333w2xunzDMWK5x/EfecAGQa9hkyAtbBR64Rixt6hXrx4iIiIMtToiIiKiQs8ggdjTp0/x888/w8XFxRCrIyIiIioScj1G7PWHewshkJqaCnNzc6xcudKglSMiIiIqzHIdiM2cOVMjEDMyMoK9vT18fX1hY2Nj0MoRERERFWa5DsSCg4PzoRpERERERU+ux4iFh4djw4YNWukbNmzAihUrDFIpIiIioqIg14FYWFgY7OzstNIdHBwwefJkg1SKiIiIqCjIdSAWGxsLDw8PrXQ3NzfExsYapFJERERERUGuAzEHBwecPXtWK/3MmTOwtbU1SKWIiIiIioJcB2I9evTAkCFDsH//fqjVaqjVauzbtw9Dhw5F9+7d86OORERERIVSru+anDhxIm7evInmzZujWLGXi2dlZSEwMJBjxIiIiIhy4Z2fNXnt2jVERUXBzMwM1apVg5ubm6Hrli/4rMnc43Pk8oANgl7DJkFa2Cj0UlifNZnrHrFsnp6e8PT0NGRdiIiIiIqUXI8R69SpE6ZMmaKVPnXqVHTp0sUglSIiIiIqCnIdiB08eBBt2rTRSm/dujUOHjxokEoRERERFQW5DsTS0tJgamqqlW5iYoKUlBSDVIqIiIioKMh1IFatWjWsW7dOK33t2rXw8vIySKWIiIiIioJcD9YfO3YsPv74Y0RHR6NZs2YAgIiICKxevRobN240eAWJiIiICqtcB2Lt27fH1q1bMXnyZGzcuBFmZmbw9vbGvn37ULJkyfyoIxEREVGh9M7ziGVLSUnBmjVrsHTpUpw6dQpqtdpQdcsXnEcs9zhHUB6wQdBr2CRICxuFXgrrPGK5HiOW7eDBgwgKCoKzszOmT5+OZs2a4ejRo4asGxEREVGhlqtLk/Hx8Vi+fDmWLl2KlJQUdO3aFRkZGdi6dSsH6hMRERHlkt49Yu3bt0fFihVx9uxZzJo1C/fu3cOcOXPys25EREREhZrePWJ//vknhgwZgoEDB/LRRkREREQGoHeP2KFDh5CamgofHx/4+vpi7ty5SEpKys+6ERERERVqegdi9erVw5IlSxAXF4cBAwZg7dq1cHZ2RlZWFvbs2YPU1NT8rCcRERFRoZOn6SuuXLmCpUuX4rfffsPjx4/RsmVLbNu2zZD1MzhOX5F7vDU9D9gg6DVsEqSFjUIvnL5Ch4oVK2Lq1Km4c+cO1qxZY6g6ERERERUJeZ7Q9b+GPWK5V7RaiIGxQdBr2CRICxuFXtgjRkREREQGxUCMiIiISCYFIhCbN28e3N3doVKp4Ovri+PHj+u13Nq1a6FQKPDRRx/lbwWJiIiI8oHsgdi6deswYsQIhIaG4vTp0/D29oa/vz8SExPfuNzNmzfx1VdfoWHDhu+ppkRERESGJXsgNmPGDPTr1w8hISHw8vLCwoULYW5ujmXLluW4jFqtRq9evTBhwgSULVv2PdaWiIiIyHBkDcQyMzNx6tQptGjRQkozMjJCixYtEBkZmeNy33//PRwcHNCnT5+3lpGRkYGUlBSNFxEREVFBIGsglpSUBLVaDUdHR410R0dHxMfH61zm0KFDWLp0KZYsWaJXGWFhYbC2tpZerq6uea43ERERkSHIfmkyN1JTU/Hpp59iyZIlsLOz02uZUaNGITk5WXrdvn07n2tJREREpJ9ichZuZ2cHY2NjJCQkaKQnJCSgVKlSWvmjo6Nx8+ZNtG/fXkrLysoCABQrVgxXrlxBuXLlNJZRKpVQKpX5UHsiIiKivJG1R8zU1BQ+Pj6IiIiQ0rKyshAREQE/Pz+t/JUqVcK5c+cQFRUlvTp06ICmTZsiKiqKlx2JiIjoP0XWHjEAGDFiBIKCglC7dm3UrVsXs2bNQnp6OkJCQgAAgYGBcHFxQVhYGFQqFapWraqxfIkSJQBAK52IiIiooJM9EOvWrRvu37+PcePGIT4+HjVq1MCuXbukAfyxsbEwMvpPDWUjIiIi0gsf+m1gfHYraWCDoNewSZAWNgq98KHfRERERGRQDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmDMSIiIiIZMJAjIiIiEgmBSIQmzdvHtzd3aFSqeDr64vjx4/nmHfJkiVo2LAhbGxsYGNjgxYtWrwxPxEREVFBJXsgtm7dOowYMQKhoaE4ffo0vL294e/vj8TERJ35Dxw4gB49emD//v2IjIyEq6srWrVqhbt3777nmhMRERHljUIIIeSsgK+vL+rUqYO5c+cCALKysuDq6oovvvgC33777VuXV6vVsLGxwdy5cxEYGPjW/CkpKbC2tkZycjKsrKzyXP/XKRQGX6Xs5G0h/3FsEPQaNgnSwkahl/w+f8tF1h6xzMxMnDp1Ci1atJDSjIyM0KJFC0RGRuq1jidPnuD58+coWbKkzs8zMjKQkpKi8SIiIiIqCGQNxJKSkqBWq+Ho6KiR7ujoiPj4eL3W8c0338DZ2VkjmHtVWFgYrK2tpZerq2ue601ERERkCLKPEcuLH3/8EWvXrsWWLVugUql05hk1ahSSk5Ol1+3bt99zLYmIiIh0KyZn4XZ2djA2NkZCQoJGekJCAkqVKvXGZadNm4Yff/wRe/fuRfXq1XPMp1QqoVQqDVJfIiIiIkOStUfM1NQUPj4+iIiIkNKysrIQEREBPz+/HJebOnUqJk6ciF27dqF27drvo6pEREREBidrjxgAjBgxAkFBQahduzbq1q2LWbNmIT09HSEhIQCAwMBAuLi4ICwsDAAwZcoUjBs3DqtXr4a7u7s0lszS0hKWlpaybQcRERFRbskeiHXr1g3379/HuHHjEB8fjxo1amDXrl3SAP7Y2FgYGf2v427BggXIzMxE586dNdYTGhqK8ePHv8+qExEREeWJ7POIvW+cRyz3ilYLMTA2CHoNmwRpYaPQC+cRIyIiIiKDYiBGREREJBMGYkREREQyYSBGREREJBMGYkREREQyYSBGREREJBMGYkREREQyYSBGREREJBMGYkREREQyYSBGREREJBMGYkREREQykf2h30RERAWVWq3G8+fP87cQN7f8Xb8cnj17p8VMTU1hZFS0+ogYiBEREb1GCIH4+Hg8fvw4/wtbuDD/y3jfYmLeaTEjIyN4eHjA1NTUwBUquBiIERERvSY7CHNwcIC5uTkUCkX+FZaenn/rlouHR64XycrKwr179xAXF4cyZcrk7z4vQBiIERERvUKtVktBmK2trdzV+W9Sqd5pMXt7e9y7dw8vXryAiYmJgStVMBWtC7FERERvkT0mzNzcXOaaFD3ZlyTVarXMNXl/GIgRERHpUFQujRUkRXGfMxAjIiIikgkDMSIiokKiyYABGDZ9ep7WsfXAAZTv2BHGvr55Xhe9HQfrExER6Sl/rpzVzvETceJkfhT4RgPCwhDSrh2GdO+O4hwnl+8YiBEREREAIO3JEyQ+fAh/Pz8429u/83oyMzOL1FxgecFLk0RERIXIC7Uag6dOhXWTJrBr0QJjFyyAEAIAkJGZia9mzYJLmzawaNgQvsHBOHDqFADgwKlTKN64MQCg2cCBUNSpI322ad8+VOnaFcr69eHeoQOmr1ypUaZ7hw6Y+MsvCAwNhVWTJujfvz8A4NChQ2jYsCHMzMzg6uqKIUOGIL0wzpuWBwzEiIiICpEVO3agmLExji9fjtlffokZq1fjl61bAQCDp05F5LlzWDtpEs6uWYMuzZsjYMgQXIuNRf3q1XFl40YAwKYpUxD355+oX706Tl26hK6jRqF7q1Y4t2YNxvfrh7ELF2L59u0a5U5buRLenp74d+VKjB07FtHR0QgICECnTp1w9uxZrFu3DocOHcLgwYPf9y4p0HhpkoiIqBBxdXTEzBEjoFAoUNHdHeeuX8fMNWvg7+eH8D/+QOz27dJlx68+/RS7IiMRvn07Jg8aBIeSJQEAJa2tUcrODgAwY9UqNK9TB2P79gUAVHBzw8WYGPz0228Ibt9eKrdZnTr48pNPXr4pVw59+/ZFr169MGzYMACAp6cnfv75ZzRu3BgLFiyA6h0nfS1sGIgREREVIvWqVtWYj8uvenVMX7UK565fh1qtRoVOnTTyZ2RmwtbaOsf1Xbp5Ex/+/yXLbA28vTFrzRqo1WoYGxsDAGpXrqyR58yZMzh79ixWrVolpQkhkJWVhZiYGFR+LX9RxUCMiIioCEh78gTGxsY49euvUvCUzdLMLM/rt3ithystLQ0DBgzAkCFDtPKWKVMmz+UVFgzEiIiICpFj589rvD967hw8y5RBzYoVoVarkfjoERrWrKn3+iq7u+PwmTMaaYfPnEGFMmW0ArpX1apVCxcvXkT58uVztwFFDAfrExERFSKxCQkYMXMmrty8iTW7d2PO+vUY2r07Kri5oVdAAALHj8fmffsQc/cujl+4gLDwcOw4dCjH9X35ySeIOHECE3/5BVdv3cKKP/7A3PXr8VX2eLAcfPPNNzhy5AgGDx6MqKgoXLt2Db///jsH67+GPWJERESFSGCbNniakYG6wcEwNjbG0O7d0b9jRwBAeGgofli6FF/Ono27iYmwK1EC9apWRbuGDXNcX61KlbA+LAzjFi7ExKVL4WRnh+8HDNAYqK9L9erV8ffff2P06NFo2LAhhBAoV64cunXrZtDt/a9TiOzJRYqIlJQUWFtbIzk5GVZWVgZff2F8XmnRaiEGxgZBr2GTKPiePXuGmJgYeHh4vJ87+06+/9nz813tnJ8W8CZv2vf5ff6WCy9NEhEREcmEgRgRERGRTBiIEREREcmEgRgRERGRTBiIEREREcmEgRgRERGRTBiIEREREcmEgRgRERGRTBiIEREREcmEgRgREVERcvnmTdQLCYGqQQPU6NlT7uoUeXzWJBERkb7e9zOqTpww+CpDFy2ChUqFKxs3wtLMDMu3b8ewGTPweP9+g5dFb8dAjIiIqAiJvnsXbRs0gJuTk0HXq1aroVAoYGTEi225wb1FRERUiOw6cgQf9O2LEk2bwrZFC7QbPhzRd+4AABR16uDUpUv4/pdfoKhTB00GDEDI998jOS0Nijp1oKhTB+MXLwYAZGRm4qtZs+DSpg0sGjaEb3AwDpw6JZWzfPt2lGjaFNv+/hteXbtC2aABYuPjZdnm/zL2iBERERUi6c+eYUTPnqju6Ym0J08wbtEidPz6a0StWoW4P/9Ei0GDEODnh68++QTmKhXCt2/HuEWLcGXjRgCApbk5AGDw1Km4GBODtZMmwdneHlv270fAkCE4t2YNPMuUAQA8efYMU379Fb+MHg1ba2s4lCwp23b/VzEQIyIiKkQ6NWum8X7ZuHGwb9kSF2/cQNXy5VHM2BiW5uYoZWcHALC2tIRCoZDeA0BsfDzC//gDsdu3w9neHgDw1aefYldkJMK3b8fkQYMAAM9fvMD8b76Bd4UK72nrCh8GYkRERIXItdhYjFu0CMfOn0dScjKysrIAALEJCahavrxe6zh3/TrUajUqdOqkkZ6RmQlba2vpvamJCap7ehqu8kUQAzEiIqJCpP2IEXBzcsKS0aPhbG+PrKwsVO3eHZnPn+u9jrQnT2BsbIxTv/4KY2Njjc8szcykv82USije952khQwDMSIiokLiwePHuHLrFpaMHo2GNWsCAA5FRb1xGVMTE6j/v9csW82KFaFWq5H46JG0HsofvGuSiIiokLCxsoKttTUWb9mC67dvY9+JExgxc+Ybl3F3ckLakyeIOH4cSY8f48mzZ6jg5oZeAQEIHD8em/ftQ8zduzh+4QLCwsOx49Ch97Q1RQMDMSIiokLCyMgIaydNwqnLl1G1e3cMnzkTPw0Z8sZl6nt747NOndDtu+9g37Ilpv76KwAgPDQUgW3a4MvZs1Gxc2d89NVXOHHxIsqUKvU+NqXIUAghhNyVeJ9SUlJgbW2N5ORkWFlZGXz9hfFSedFqIQbGBkGvYZMo+J49e4aYmBh4eHhApVLlf4EnT+Z/Ge9b7drvtNib9n1+n7/lwh4xIiIiIpkwECMiIiKSCQMxIiIiIpkwECMiIiKSCQMxIiIiIpkwECMiItIh67VJTin/FbGJHABwZn0iIiINpqamMDIywr1792Bvbw9TU1M+xie3nj3L9SJCCNy/fx8KhQImJib5UKmCiYEYERHRK4yMjODh4YG4uDjcu3cv/wtMSsr/Mt63mJh3WkyhUKB06dJaz7cszBiIERERvcbU1BRlypTBixcvoFar87ew1q3zd/1yuHz5nRYzMTEpUkEYwECMiIhIp+xLZPl+mezWrfxdvxzexxMJCokCMVh/3rx5cHd3h0qlgq+vL44fP/7G/Bs2bEClSpWgUqlQrVo17Ny58z3VlIiIiMhwZA/E1q1bhxEjRiA0NBSnT5+Gt7c3/P39kZiYqDP/kSNH0KNHD/Tp0wf//vsvPvroI3z00Uc4f/78e645ERERUd7I/tBvX19f1KlTB3PnzgXw8nZhV1dXfPHFF/j222+18nfr1g3p6en4448/pLR69eqhRo0aWLhw4VvL40O/c68I3k1sOGwQ9Bo2CdLCRqGXwvrQb1nHiGVmZuLUqVMYNWqUlGZkZIQWLVogMjJS5zKRkZEYMWKERpq/vz+2bt2qM39GRgYyMjKk98nJyQBe/kNJP9xVpIENgl7DJkFa8qFRZJ+3C9tcY7IGYklJSVCr1XB0dNRId3R0xOUc7riIj4/XmT8+Pl5n/rCwMEyYMEEr3dXV9R1rXfRYW8tdAypQ2CDoNWwSpCUfG0VqaiqsC1GjK/R3TY4aNUqjBy0rKwsPHz6Era0tJ+grBFJSUuDq6orbt28Xqq5qIjIMHiMKDyEEUlNT4ezsLHdVDErWQMzOzg7GxsZISEjQSE9ISECpUqV0LlOqVKlc5VcqlVAqlRppJUqUePdKU4FkZWXFgywR5YjHiMKhMPWEZZP1rklTU1P4+PggIiJCSsvKykJERAT8/Px0LuPn56eRHwD27NmTY34iIiKigkr2S5MjRoxAUFAQateujbp162LWrFlIT09HSEgIACAwMBAuLi4ICwsDAAwdOhSNGzfG9OnT0bZtW6xduxYnT57E4sWL5dwMIiIiolyTPRDr1q0b7t+/j3HjxiE+Ph41atTArl27pAH5sbGxMDL6X8dd/fr1sXr1aowZMwbfffcdPD09sXXrVlStWlWuTSAZKZVKhIaGal1+JiICeIyggk/2ecSIiIiIiirZZ9YnIiIiKqoYiBERERHJhIEYERERkUwYiBERERHJhIEYvRfLly8vtBPpBgcH46OPPtI7/4EDB6BQKPD48eN8qxORPhQKRY7P6TWkJk2aYNiwYdJ7d3d3zJo1S3ofHx+Pli1bwsLCQjpOGKJuuf1uEsmBgRgBeHnAUigU0svW1hYBAQE4e/asQdbfrVs3XL16Ve/8TZo00ahP9uvFixdSnuvXryMkJASlS5eGUqmEh4cHevTogZMnT0p5spc7evSoxvozMjKkx1wdOHAgz9tHVBDdv38fAwcORJkyZaBUKlGqVCn4+/vj8OHDAIC4uDi0bt36vdfrxIkT6N+/v/R+5syZiIuLQ1RUlHScyI+6vXqcMzExgYeHB0aOHIlnz55p5HtbELhkyRJ4e3vD0tISJUqUQM2aNaW5LrPLMWQA+HogS4ULAzGSBAQEIC4uDnFxcYiIiECxYsXQrl07g6zbzMwMDg4OuVqmX79+Un2yX8WKvZz67uTJk/Dx8cHVq1exaNEiXLx4EVu2bEGlSpXw5ZdfaqzH1dUV4eHhGmlbtmyBpaVl3jaKqIDr1KkT/v33X6xYsQJXr17Ftm3b0KRJEzx48ADAy0fGyTG/lr29PczNzaX30dHR8PHxgaenp3ScyK+6ZR/nbty4gZkzZ2LRokUIDQ3Ve/lly5Zh2LBhGDJkCKKionD48GGMHDkSaWlpBq9rZmZmgV4fGYggEkIEBQWJDz/8UCPtn3/+EQBEYmKiEEKIkSNHCk9PT2FmZiY8PDzEmDFjRGZmppQ/KipKNGnSRFhaWorixYuLWrVqiRMnTgghhAgPDxfW1tYa69+2bZuoXbu2UCqVwtbWVnz00UfSZ40bNxZDhw7VWdesrCxRpUoV4ePjI9Rqtdbnjx49kv4GIMaMGSOsrKzEkydPpPSWLVuKsWPHCgBi//79UvrZs2dF06ZNhUqlEiVLlhT9+vUTqamp0ucvXrwQw4cPF9bW1qJkyZLi66+/FoGBgRr7Tq1Wi8mTJwt3d3ehUqlE9erVxYYNG6TP9+/fLwBo1JPI0B49eiQAiAMHDuSYB4DYsmWLEEKImJgYAUCsW7dOfPDBB0KlUonatWuLK1euiOPHjwsfHx9hYWEhAgICpGOCEP87dowfP17Y2dmJ4sWLiwEDBoiMjAwpz+vfZzc3NzFz5kzpbwDSKygoSKtuQggRGxsrunTpIqytrYWNjY3o0KGDiImJkT7X57up6zj38ccfi5o1a+a4X1734YcfiuDg4Bz3aWhoqMb2vHqMedsxNDQ0VHh7e4slS5YId3d3oVAoRFBQkNb6srf73LlzIiAgQFhYWAgHBwfxySefiPv372vs90GDBomhQ4cKW1tb0aRJkxzrTfJhjxjplJaWhpUrV6J8+fKwtbUFABQvXhzLly/HxYsXMXv2bCxZsgQzZ86UlunVqxdKly6NEydO4NSpU/j2229hYmKic/07duxAx44d0aZNG/z777+IiIhA3bp19apbVFQULly4gC+//FLjqQvZXh+L5uPjA3d3d2zatAnAy6c1HDx4EJ9++qlGvvT0dPj7+8PGxgYnTpzAhg0bsHfvXgwePFjKM336dCxfvhzLli3DoUOH8PDhQ2zZskVjPWFhYfj111+xcOFCXLhwAcOHD8cnn3yCv//+W6/tIzIES0tLWFpaYuvWrcjIyNB7udDQUIwZMwanT59GsWLF0LNnT4wcORKzZ8/GP//8g+vXr2PcuHEay0RERODSpUs4cOAA1qxZg82bN2PChAl6lXfixAkEBASga9euiIuLw+zZs7XyPH/+HP7+/ihevDj++ecfHD58GJaWlggICJB6efT5br7u/PnzOHLkCExNTfXcOy976o4ePYpbt27p/Pyrr75C165dNa4w1K9fH8Dbj6HAyyEXmzZtwubNmxEVFYXZs2fDz89P4wqBq6srHj9+jGbNmqFmzZo4efIkdu3ahYSEBHTt2lVjfStWrICpqSkOHz6MhQsX6r2d9B7JHQlSwRAUFCSMjY2FhYWFsLCwEACEk5OTOHXqVI7L/PTTT8LHx0d6X7x4cbF8+XKdeV/vEfPz8xO9evXKcd2NGzcWJiYmUn0sLCzEiBEjhBBCrFu3TgAQp0+ffut24f9/2c6aNUs0bdpUCCHEhAkTRMeOHaUeg+xfq4sXLxY2NjYiLS1NWn7Hjh3CyMhIxMfHCyGEcHJyElOnTpU+f/78uShdurT0K/vZs2fC3NxcHDlyRKMeffr0ET169BBCsEeM3p+NGzcKGxsboVKpRP369cWoUaPEmTNnpM+ho0fsl19+kT5fs2aNACAiIiKktLCwMFGxYkXpfVBQkChZsqRIT0+X0hYsWCAsLS2lHus39YgJ8bKXKbsnTFfdfvvtN1GxYkWRlZUlfZ6RkSHMzMzE7t27hRBv/25m1zX7OKdUKgUAYWRkJDZu3Jhj2a+7d++eqFevngAgKlSoIIKCgsS6des0eud19bzp8voxNDQ0VJiYmGj0OAqh+wrBxIkTRatWrTTSbt++LQCIK1euSMu93ttHBQ97xEjStGlTREVFISoqCsePH4e/vz9at24t/fJbt24dGjRogFKlSsHS0hJjxoxBbGystPyIESPQt29ftGjRAj/++COio6NzLCsqKgrNmzd/Y3169eol1ScqKgqjRo0CAIh3eCrXJ598gsjISNy4cQPLly9H7969tfJcunQJ3t7esLCwkNIaNGiArKwsXLlyBcnJyYiLi4Ovr6/0ebFixVC7dm3p/fXr1/HkyRO0bNlS6pGwtLTEr7/++sb9QZQfOnXqhHv37mHbtm0ICAjAgQMHUKtWLSxfvjzHZapXry79nf3M32rVqmmkJSYmaizj7e2tMebLz88PaWlpuH37tkG248yZM7h+/TqKFy8ufadKliyJZ8+eITo6Wq/vZrbs49yxY8cQFBSEkJAQdOrUSe+6ODk5ITIyEufOncPQoUPx4sULBAUFISAgAFlZWW9c9m3HUABwc3ODvb39W+tx5swZ7N+/X+M4U6lSJQDQONb4+PjovW0kD9kf+k0Fh4WFBcqXLy+9/+WXX2BtbY0lS5agbdu26NWrFyZMmAB/f39YW1tj7dq1mD59upR//Pjx6NmzJ3bs2IE///wToaGhWLt2LTp27KhVlpmZ2VvrY21trVGfbBUqVAAAXL58GTVr1tRr22xtbdGuXTv06dMHz549Q+vWrZGamqrXsrmRPWB3x44dcHFx0fiMDx0mOahUKrRs2RItW7bE2LFj0bdvX4SGhiI4OFhn/leHEygUCp1pbws4DC0tLQ0+Pj5YtWqV1mf6BC2vevU4t2zZMnh7e2Pp0qXo06dPrtZTtWpVVK1aFZ9//jk+++wzNGzYEH///TeaNm2qM39kZORbj6HZ9dNHWloa2rdvjylTpmh95uTklOv1kXzYI0Y5UigUMDIywtOnT3HkyBG4ublh9OjRqF27Njw9PXWOkahQoQKGDx+Ov/76Cx9//LHW3YrZqlevjoiIiHeqV40aNeDl5YXp06frPCHkND9X7969ceDAAQQGBsLY2Fjr88qVK+PMmTNIT0+X0g4fPgwjIyNUrFgR1tbWcHJywrFjx6TPX7x4gVOnTknvvby8oFQqERsbi/Lly2u8XF1d32l7iQzJy8tLo40bwpkzZ/D06VPp/dGjR2FpaWmwNl+rVi1cu3YNDg4OWt8ra2trvb6buhgZGeG7777DmDFjNOqfW15eXgAg7VdTU1Oo1WqNPPoeQ3XRtb5atWrhwoULcHd319onDL7+WxiIkSQjIwPx8fGIj4/HpUuX8MUXX0i/ujw9PREbG4u1a9ciOjoaP//8s8ZA2KdPn2Lw4ME4cOAAbt26hcOHD+PEiROoXLmyzrJCQ0OxZs0ahIaG4tKlSzh37pzOX3a6KBQKhIeH4+rVq2jYsCF27tyJGzdu4OzZs5g0aRI+/PBDncsFBATg/v37+P7773V+3qtXL6hUKgQFBeH8+fPYv38/vvjiC3z66afSJZqhQ4fixx9/xNatW3H58mV8/vnnGoFf8eLF8dVXX2H48OFYsWIFoqOjcfr0acyZMwcrVqzQa/uIDOHBgwdo1qwZVq5cibNnzyImJgYbNmzA1KlTc/yOvKvMzEz06dMHFy9exM6dOxEaGorBgwfrvJnmXfTq1Qt2dnb48MMP8c8//yAmJgYHDhzAkCFDcOfOHQBv/27mpEuXLjA2Nsa8efM00mNiYjSGRkRFRSE9PR0DBw7ExIkTcfjwYdy6dQtHjx5FYGAg7O3t4efnB+DlhLVnz57FlStXkJSUhOfPn7/1GPom7u7uOHbsGG7evImkpCRkZWVh0KBBePjwIXr06IETJ04gOjoau3fvRkhIiFbQRgUbL02SZNeuXVKXdvHixVGpUiVs2LABTZo0AQAMHz4cgwcPRkZGBtq2bYuxY8di/PjxAABjY2M8ePAAgYGBSEhIgJ2dHT7++OMc75xq0qQJNmzYgIkTJ+LHH3+ElZUVGjVqpHdd69ati5MnT2LSpEno168fkpKS4OTkhPr162vM2P0qhUIBOzu7HNdpbm6O3bt3Y+jQoahTpw7Mzc3RqVMnzJgxQ8rz5ZdfIi4uDkFBQTAyMkLv3r3RsWNHJCcnS3kmTpwIe3t7hIWF4caNGyhRogRq1aqF7777Tu/tI8orS0tL+Pr6YubMmYiOjsbz58/h6uqKfv36GbwtNm/eHJ6enmjUqBEyMjLQo0cP6dhgCObm5jh48CC++eYbfPzxx0hNTYWLiwuaN28OKysrAPp9N3UpVqwYBg8ejKlTp2LgwIFSb9KIESO08v7zzz9o0aIFli1bhgULFuDBgwews7ODn58fIiIipDvM+/XrhwMHDqB27dpIS0vD/v370aFDhzceQ9/kq6++QlBQELy8vPD06VPExMTA3d0dhw8fxjfffINWrVohIyMDbm5uCAgIMFgATO+HQrzLyGciIiK8nEX+8ePH7+VRSUSFEcNmIiIiIpkwECMiIiKSCS9NEhEREcmEPWJEREREMmEgRkRERCQTBmJEREREMmEgRkRERCQTBmJEREREMmEgRkRERCQTBmJEREREMmEgRkRERCST/wPVXI9hiZ1pUAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax1 = plt.subplots()\n",
    "# ax2 = ax1.twinx() \n",
    "ax1.bar([0, 2],  [.97, .9717], width=.4, color='blue', label='before');\n",
    "# ax1.bar([1, 3], [.1160, .1142], width=.4, color='green', label='after');\n",
    "ax1.bar([1, 3], [0.9683, 0.9758], width=.4, color='red', label='after');\n",
    "ax1.set_ylabel('Accuracy', color='black');\n",
    "# ax1.tick_params(axis='y', labelcolor='orange');\n",
    "# ax2.set_ylabel('Accuracy', color='b');\n",
    "# ax2.tick_params(axis='y', labelcolor='b');\n",
    "# ax1.set_xticks([0, 2], ['BasicFCModel', 'SimplifiedRLStarter'], rotation=5);\n",
    "ax1.set_xticks([.5, 2.5], ['BasicFCModel', 'SimplifiedRLStarter']);\n",
    "for ind, val in zip(range(4), [.97, 0.9683, .9717, 0.9758]):\n",
    "    ax = ax1 #if ind % 2 == 0 else ax2\n",
    "    h_add = .005 #if ind % 2 == 0 else .005\n",
    "    ax.text(ind-.125, val+h_add, s=str(round(val, 3)))\n",
    "plt.title('Accuracy Comparison before and after Feature Selection on Local Test');\n",
    "plt.legend(loc=4)\n",
    "plt.savefig('./extracted_features/acc_comparison.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3765,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_importance['SimplifiedRLStarter'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_importance['BasicFCModel'][0][1463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992460058629061"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = fe_importance['BasicFCModel'][0]\n",
    "\n",
    "np.sum(imp[np.argsort(imp)[::-1][:800]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    1,    3, ..., 2346, 2348, 2349]),)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(fe_importance['BasicFCModel'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(np.asarray(fe_importance['BasicFCModel'][0])[np.nonzero(fe_importance['BasicFCModel'][0])[0]], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_level = np.argsort(fe_importance['BasicFCModel'][0])[::-1][:np.count_nonzero(fe_importance['BasicFCModel'][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.43464973e-02, 7.12541787e-02, 6.02651122e-02, ...,\n",
       "       2.85341630e-10, 1.57271242e-10, 1.38377875e-19])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(fe_importance['BasicFCModel'][0])[importance_level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 2346, 2348, 2349])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(fe_importance['BasicFCModel'][0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_imp_ind = {'BasicFCModel':2200, 'SimplifiedRLStarter':3200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_importance_set = {}\n",
    "for k, vs in fe_importance.items():\n",
    "    imp = set(np.argsort(vs[0])[::-1][:fe_imp_ind[k]])\n",
    "    for v in vs:\n",
    "        valid_inds = np.argsort(v)[::-1][:fe_imp_ind[k]]\n",
    "        imp = imp.intersection(valid_inds)\n",
    "    fe_importance_set[k] = imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicFCModel - 795\n",
      "SimplifiedRLStarter - 1081\n"
     ]
    }
   ],
   "source": [
    "for k, v in fe_importance_set.items():\n",
    "    print(f'{k} - {len(v)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in fe_importance_set.items():\n",
    "    fe_importance_set[k] = list(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 1878)\n",
      "(120, 2466)\n"
     ]
    }
   ],
   "source": [
    "X_fe_reduced = {}\n",
    "for k, v in X.items():\n",
    "    X_fe_reduced[k] = np.asarray(v)[:, fe_importance_set[k]]\n",
    "    print(X_fe_reduced[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in fe_importance_set.items():\n",
    "    fe_importance_set[k] = [int(l) for l in list(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 795)\n",
      "(120, 1081)\n"
     ]
    }
   ],
   "source": [
    "X_fe_reduced = {}\n",
    "for k, v in X.items():\n",
    "    X_fe_reduced[k] = np.asarray(v)[:, fe_importance_set[k]]\n",
    "    print(X_fe_reduced[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(fe_importance_set, open(os.path.join(OUTPUT_FILEDIR, 'fe_ind2.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicFCModel 0.11665780598913689 0.9641666666666667\n",
      "SimplifiedRLStarter 0.10297708796412654 0.9791666666666665\n"
     ]
    }
   ],
   "source": [
    "for k, v in X_fe_reduced.items():\n",
    "    cen, acc = bootstrap_performance(v, y[k], clf, n=50, test_size=.2)\n",
    "    print(k, np.mean(cen), np.mean(acc))\n",
    "    # fe_importance[k] = fe_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.111, max_depth=2, min_samples_leaf=6, min_samples_split=16, subsample=.6, max_features=300)\n",
    "# param={'max_depth': range(2, 9, 2), 'min_samples_leaf': range(2, 35, 4), 'min_samples_split': range(16, 65, 4), 'max_features': range(200, 411, 20), 'subsample': np.arange(.6, .91, .02)}\n",
    "# param = {'learning_rate':np.arange(.05, .301, .05), 'n_estimators':range(100, 2001, 25)}\n",
    "param = {'learning_rate':np.arange(.001, .301, .001), 'n_estimators':range(100, 3001, 25)}\n",
    "# param = {'learning_rate':[.015, .03, .005, .01, .0025, .025, .003, .0015, .0005], 'n_estimators':[125, 63, 375, 187, 750, 75, 630, 1250, 3750]}\n",
    "gsearch = GridSearchCV(estimator=clf, param_grid=param, scoring=['neg_log_loss', 'accuracy'], n_jobs=10, cv=5, refit=False);\n",
    "gsearch.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_result = pd.DataFrame(gsearch.cv_results_).sort_values(by=['rank_test_neg_log_loss', 'rank_test_accuracy'])\n",
    "gsearch_result.to_csv(os.path.join(OUTPUT_FILEDIR, f'gsearch_result_{k}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_neg_log_loss</th>\n",
       "      <th>split1_test_neg_log_loss</th>\n",
       "      <th>split2_test_neg_log_loss</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>0.078553</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.033</td>\n",
       "      <td>125</td>\n",
       "      <td>{'learning_rate': 0.033, 'n_estimators': 125}</td>\n",
       "      <td>-0.341112</td>\n",
       "      <td>-0.549322</td>\n",
       "      <td>-0.706908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.237398</td>\n",
       "      <td>32209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8073</th>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.07</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.07, 'n_estimators': 100}</td>\n",
       "      <td>-0.356271</td>\n",
       "      <td>-0.657309</td>\n",
       "      <td>-0.693475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131424</td>\n",
       "      <td>2</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.213293</td>\n",
       "      <td>27848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12870</th>\n",
       "      <td>0.071993</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.111</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.111, 'n_estimators': 100}</td>\n",
       "      <td>-0.228063</td>\n",
       "      <td>-0.557090</td>\n",
       "      <td>-0.718041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212997</td>\n",
       "      <td>3</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>0.093953</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>0.062990</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.051</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.051000000000000004, 'n_est...</td>\n",
       "      <td>-0.352012</td>\n",
       "      <td>-0.573338</td>\n",
       "      <td>-0.721012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142894</td>\n",
       "      <td>4</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.172357</td>\n",
       "      <td>20042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5968</th>\n",
       "      <td>0.079375</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.052</td>\n",
       "      <td>125</td>\n",
       "      <td>{'learning_rate': 0.052000000000000005, 'n_est...</td>\n",
       "      <td>-0.273112</td>\n",
       "      <td>-0.569925</td>\n",
       "      <td>-0.681151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193816</td>\n",
       "      <td>5</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.213293</td>\n",
       "      <td>27848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7839</th>\n",
       "      <td>0.063560</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.068</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.068, 'n_estimators': 100}</td>\n",
       "      <td>-0.273675</td>\n",
       "      <td>-0.567905</td>\n",
       "      <td>-0.705889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190345</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>9553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>0.062784</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.027000000000000003, 'n_est...</td>\n",
       "      <td>-0.462242</td>\n",
       "      <td>-0.584624</td>\n",
       "      <td>-0.601283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103198</td>\n",
       "      <td>7</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.220129</td>\n",
       "      <td>20042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3393</th>\n",
       "      <td>0.062645</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.03</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.030000000000000002, 'n_est...</td>\n",
       "      <td>-0.405477</td>\n",
       "      <td>-0.606294</td>\n",
       "      <td>-0.640579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122382</td>\n",
       "      <td>8</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.220129</td>\n",
       "      <td>20042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>0.094876</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.04</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.04, 'n_estimators': 150}</td>\n",
       "      <td>-0.285554</td>\n",
       "      <td>-0.617364</td>\n",
       "      <td>-0.692358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186864</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.669444</td>\n",
       "      <td>0.207573</td>\n",
       "      <td>19652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>0.125181</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.012</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.012, 'n_estimators': 200}</td>\n",
       "      <td>-0.468924</td>\n",
       "      <td>-0.609551</td>\n",
       "      <td>-0.642298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088974</td>\n",
       "      <td>10</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.220129</td>\n",
       "      <td>20042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.173247</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.018</td>\n",
       "      <td>275</td>\n",
       "      <td>{'learning_rate': 0.018000000000000002, 'n_est...</td>\n",
       "      <td>-0.339807</td>\n",
       "      <td>-0.590287</td>\n",
       "      <td>-0.642547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159188</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.663889</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>20242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>0.126691</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.024</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.024, 'n_estimators': 200}</td>\n",
       "      <td>-0.384917</td>\n",
       "      <td>-0.583945</td>\n",
       "      <td>-0.703404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130986</td>\n",
       "      <td>12</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.213293</td>\n",
       "      <td>27848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>0.171332</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.014</td>\n",
       "      <td>275</td>\n",
       "      <td>{'learning_rate': 0.014000000000000002, 'n_est...</td>\n",
       "      <td>-0.387363</td>\n",
       "      <td>-0.599030</td>\n",
       "      <td>-0.646904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131902</td>\n",
       "      <td>13</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.619444</td>\n",
       "      <td>0.206679</td>\n",
       "      <td>32524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>0.062593</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.034</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.034, 'n_estimators': 100}</td>\n",
       "      <td>-0.441784</td>\n",
       "      <td>-0.548615</td>\n",
       "      <td>-0.659189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118922</td>\n",
       "      <td>14</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.235309</td>\n",
       "      <td>9631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>0.264650</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.01</td>\n",
       "      <td>425</td>\n",
       "      <td>{'learning_rate': 0.010000000000000002, 'n_est...</td>\n",
       "      <td>-0.381971</td>\n",
       "      <td>-0.593391</td>\n",
       "      <td>-0.679527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137694</td>\n",
       "      <td>15</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.213293</td>\n",
       "      <td>27848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>0.063471</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.044</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.044000000000000004, 'n_est...</td>\n",
       "      <td>-0.380761</td>\n",
       "      <td>-0.611077</td>\n",
       "      <td>-0.694085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141112</td>\n",
       "      <td>16</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.220129</td>\n",
       "      <td>20042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>0.109656</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.01</td>\n",
       "      <td>175</td>\n",
       "      <td>{'learning_rate': 0.010000000000000002, 'n_est...</td>\n",
       "      <td>-0.479376</td>\n",
       "      <td>-0.604416</td>\n",
       "      <td>-0.640274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085980</td>\n",
       "      <td>17</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.220129</td>\n",
       "      <td>20042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076</th>\n",
       "      <td>0.109031</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.07</td>\n",
       "      <td>175</td>\n",
       "      <td>{'learning_rate': 0.07, 'n_estimators': 175}</td>\n",
       "      <td>-0.345884</td>\n",
       "      <td>-0.644488</td>\n",
       "      <td>-0.770121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147905</td>\n",
       "      <td>18</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.081271</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>0.153625</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.02</td>\n",
       "      <td>225</td>\n",
       "      <td>{'learning_rate': 0.02, 'n_estimators': 225}</td>\n",
       "      <td>-0.353594</td>\n",
       "      <td>-0.574557</td>\n",
       "      <td>-0.712533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151401</td>\n",
       "      <td>19</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.174271</td>\n",
       "      <td>27288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>0.093616</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.036</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.036000000000000004, 'n_est...</td>\n",
       "      <td>-0.323361</td>\n",
       "      <td>-0.591987</td>\n",
       "      <td>-0.696943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165395</td>\n",
       "      <td>20</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.220129</td>\n",
       "      <td>20042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3745        0.078553      0.000611         0.001505        0.000028   \n",
       "8073        0.063099      0.001126         0.001582        0.000049   \n",
       "12870       0.071993      0.008178         0.001946        0.000462   \n",
       "5850        0.062990      0.000678         0.001561        0.000037   \n",
       "5968        0.079375      0.001292         0.001526        0.000033   \n",
       "7839        0.063560      0.001277         0.001533        0.000042   \n",
       "3042        0.062784      0.000799         0.001521        0.000027   \n",
       "3393        0.062645      0.000817         0.001481        0.000028   \n",
       "4565        0.094876      0.001898         0.001575        0.000037   \n",
       "1291        0.125181      0.002050         0.001607        0.000009   \n",
       "1996        0.173247      0.004348         0.001700        0.000041   \n",
       "2695        0.126691      0.002265         0.001628        0.000015   \n",
       "1528        0.171332      0.002224         0.001666        0.000027   \n",
       "3861        0.062593      0.000824         0.001487        0.000030   \n",
       "1066        0.264650      0.003048         0.001782        0.000038   \n",
       "5031        0.063471      0.001508         0.001529        0.000026   \n",
       "1056        0.109656      0.001659         0.001603        0.000023   \n",
       "8076        0.109031      0.001364         0.001582        0.000015   \n",
       "2228        0.153625      0.006548         0.002024        0.000369   \n",
       "4097        0.093616      0.001284         0.001498        0.000011   \n",
       "\n",
       "      param_learning_rate param_n_estimators  \\\n",
       "3745                0.033                125   \n",
       "8073                 0.07                100   \n",
       "12870               0.111                100   \n",
       "5850                0.051                100   \n",
       "5968                0.052                125   \n",
       "7839                0.068                100   \n",
       "3042                0.027                100   \n",
       "3393                 0.03                100   \n",
       "4565                 0.04                150   \n",
       "1291                0.012                200   \n",
       "1996                0.018                275   \n",
       "2695                0.024                200   \n",
       "1528                0.014                275   \n",
       "3861                0.034                100   \n",
       "1066                 0.01                425   \n",
       "5031                0.044                100   \n",
       "1056                 0.01                175   \n",
       "8076                 0.07                175   \n",
       "2228                 0.02                225   \n",
       "4097                0.036                150   \n",
       "\n",
       "                                                  params  \\\n",
       "3745       {'learning_rate': 0.033, 'n_estimators': 125}   \n",
       "8073        {'learning_rate': 0.07, 'n_estimators': 100}   \n",
       "12870      {'learning_rate': 0.111, 'n_estimators': 100}   \n",
       "5850   {'learning_rate': 0.051000000000000004, 'n_est...   \n",
       "5968   {'learning_rate': 0.052000000000000005, 'n_est...   \n",
       "7839       {'learning_rate': 0.068, 'n_estimators': 100}   \n",
       "3042   {'learning_rate': 0.027000000000000003, 'n_est...   \n",
       "3393   {'learning_rate': 0.030000000000000002, 'n_est...   \n",
       "4565        {'learning_rate': 0.04, 'n_estimators': 150}   \n",
       "1291       {'learning_rate': 0.012, 'n_estimators': 200}   \n",
       "1996   {'learning_rate': 0.018000000000000002, 'n_est...   \n",
       "2695       {'learning_rate': 0.024, 'n_estimators': 200}   \n",
       "1528   {'learning_rate': 0.014000000000000002, 'n_est...   \n",
       "3861       {'learning_rate': 0.034, 'n_estimators': 100}   \n",
       "1066   {'learning_rate': 0.010000000000000002, 'n_est...   \n",
       "5031   {'learning_rate': 0.044000000000000004, 'n_est...   \n",
       "1056   {'learning_rate': 0.010000000000000002, 'n_est...   \n",
       "8076        {'learning_rate': 0.07, 'n_estimators': 175}   \n",
       "2228        {'learning_rate': 0.02, 'n_estimators': 225}   \n",
       "4097   {'learning_rate': 0.036000000000000004, 'n_est...   \n",
       "\n",
       "       split0_test_neg_log_loss  split1_test_neg_log_loss  \\\n",
       "3745                  -0.341112                 -0.549322   \n",
       "8073                  -0.356271                 -0.657309   \n",
       "12870                 -0.228063                 -0.557090   \n",
       "5850                  -0.352012                 -0.573338   \n",
       "5968                  -0.273112                 -0.569925   \n",
       "7839                  -0.273675                 -0.567905   \n",
       "3042                  -0.462242                 -0.584624   \n",
       "3393                  -0.405477                 -0.606294   \n",
       "4565                  -0.285554                 -0.617364   \n",
       "1291                  -0.468924                 -0.609551   \n",
       "1996                  -0.339807                 -0.590287   \n",
       "2695                  -0.384917                 -0.583945   \n",
       "1528                  -0.387363                 -0.599030   \n",
       "3861                  -0.441784                 -0.548615   \n",
       "1066                  -0.381971                 -0.593391   \n",
       "5031                  -0.380761                 -0.611077   \n",
       "1056                  -0.479376                 -0.604416   \n",
       "8076                  -0.345884                 -0.644488   \n",
       "2228                  -0.353594                 -0.574557   \n",
       "4097                  -0.323361                 -0.591987   \n",
       "\n",
       "       split2_test_neg_log_loss  ...  std_test_neg_log_loss  \\\n",
       "3745                  -0.706908  ...               0.140328   \n",
       "8073                  -0.693475  ...               0.131424   \n",
       "12870                 -0.718041  ...               0.212997   \n",
       "5850                  -0.721012  ...               0.142894   \n",
       "5968                  -0.681151  ...               0.193816   \n",
       "7839                  -0.705889  ...               0.190345   \n",
       "3042                  -0.601283  ...               0.103198   \n",
       "3393                  -0.640579  ...               0.122382   \n",
       "4565                  -0.692358  ...               0.186864   \n",
       "1291                  -0.642298  ...               0.088974   \n",
       "1996                  -0.642547  ...               0.159188   \n",
       "2695                  -0.703404  ...               0.130986   \n",
       "1528                  -0.646904  ...               0.131902   \n",
       "3861                  -0.659189  ...               0.118922   \n",
       "1066                  -0.679527  ...               0.137694   \n",
       "5031                  -0.694085  ...               0.141112   \n",
       "1056                  -0.640274  ...               0.085980   \n",
       "8076                  -0.770121  ...               0.147905   \n",
       "2228                  -0.712533  ...               0.151401   \n",
       "4097                  -0.696943  ...               0.165395   \n",
       "\n",
       "       rank_test_neg_log_loss  split0_test_accuracy  split1_test_accuracy  \\\n",
       "3745                        1              0.888889              0.777778   \n",
       "8073                        2              0.888889              0.666667   \n",
       "12870                       3              0.888889              0.666667   \n",
       "5850                        4              0.888889              0.777778   \n",
       "5968                        5              0.888889              0.666667   \n",
       "7839                        6              1.000000              0.666667   \n",
       "3042                        7              0.888889              0.777778   \n",
       "3393                        8              0.888889              0.777778   \n",
       "4565                        9              1.000000              0.555556   \n",
       "1291                       10              0.888889              0.777778   \n",
       "1996                       11              1.000000              0.777778   \n",
       "2695                       12              0.888889              0.666667   \n",
       "1528                       13              0.888889              0.666667   \n",
       "3861                       14              0.888889              0.888889   \n",
       "1066                       15              0.888889              0.666667   \n",
       "5031                       16              0.888889              0.777778   \n",
       "1056                       17              0.888889              0.777778   \n",
       "8076                       18              0.888889              0.666667   \n",
       "2228                       19              0.888889              0.666667   \n",
       "4097                       20              0.888889              0.777778   \n",
       "\n",
       "       split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "3745               0.444444                 0.750                 0.250   \n",
       "8073               0.666667                 0.750                 0.250   \n",
       "12870              0.666667                 0.750                 0.625   \n",
       "5850               0.666667                 0.625                 0.375   \n",
       "5968               0.666667                 0.750                 0.250   \n",
       "7839               0.666667                 0.750                 0.375   \n",
       "3042               0.666667                 0.750                 0.250   \n",
       "3393               0.666667                 0.750                 0.250   \n",
       "4565               0.666667                 0.750                 0.375   \n",
       "1291               0.666667                 0.750                 0.250   \n",
       "1996               0.666667                 0.625                 0.250   \n",
       "2695               0.666667                 0.750                 0.250   \n",
       "1528               0.666667                 0.625                 0.250   \n",
       "3861               0.666667                 0.750                 0.250   \n",
       "1066               0.666667                 0.750                 0.250   \n",
       "5031               0.666667                 0.750                 0.250   \n",
       "1056               0.666667                 0.750                 0.250   \n",
       "8076               0.666667                 0.750                 0.750   \n",
       "2228               0.555556                 0.750                 0.375   \n",
       "4097               0.666667                 0.750                 0.250   \n",
       "\n",
       "       mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "3745             0.622222           0.237398               32209  \n",
       "8073             0.644444           0.213293               27848  \n",
       "12870            0.719444           0.093953                2464  \n",
       "5850             0.666667           0.172357               20042  \n",
       "5968             0.644444           0.213293               27848  \n",
       "7839             0.691667           0.200000                9553  \n",
       "3042             0.666667           0.220129               20042  \n",
       "3393             0.666667           0.220129               20042  \n",
       "4565             0.669444           0.207573               19652  \n",
       "1291             0.666667           0.220129               20042  \n",
       "1996             0.663889           0.244444               20242  \n",
       "2695             0.644444           0.213293               27848  \n",
       "1528             0.619444           0.206679               32524  \n",
       "3861             0.688889           0.235309                9631  \n",
       "1066             0.644444           0.213293               27848  \n",
       "5031             0.666667           0.220129               20042  \n",
       "1056             0.666667           0.220129               20042  \n",
       "8076             0.744444           0.081271                 208  \n",
       "2228             0.647222           0.174271               27288  \n",
       "4097             0.666667           0.220129               20042  \n",
       "\n",
       "[20 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch_result.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3745     0.622222\n",
       "8073     0.644444\n",
       "12870    0.719444\n",
       "5850     0.666667\n",
       "5968     0.644444\n",
       "           ...   \n",
       "29586    0.619444\n",
       "33249    0.650000\n",
       "34539    0.700000\n",
       "34500    0.630556\n",
       "34179    0.652778\n",
       "Name: mean_test_accuracy, Length: 35100, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch_result['mean_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3745     32209\n",
       "8073     27848\n",
       "12870     2464\n",
       "5850     20042\n",
       "5968     27848\n",
       "         ...  \n",
       "29586    32524\n",
       "33249    24445\n",
       "34539     3014\n",
       "34500    28522\n",
       "34179    21022\n",
       "Name: rank_test_accuracy, Length: 35100, dtype: int32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch_result['rank_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3745    -0.596133\n",
       "8073    -0.608179\n",
       "12870   -0.611247\n",
       "5850    -0.614984\n",
       "5968    -0.619903\n",
       "           ...   \n",
       "29586   -3.528528\n",
       "33249   -3.534978\n",
       "34539   -3.559429\n",
       "34500   -3.560073\n",
       "34179   -3.623068\n",
       "Name: mean_test_neg_log_loss, Length: 35100, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch_result['mean_test_neg_log_loss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obj_det_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e782c4fbc36884394c9170738cdc99c03bcf42c881b0742568b6d97ce29ddb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
